/**
 * Check robots.txt and rate limit information for Replicate
 */

async function checkRobotsTxt() {
  console.log("ðŸ¤– Checking robots.txt files...\n");

  try {
    // Check main Replicate site
    console.log("ðŸ“„ Checking https://replicate.com/robots.txt");
    const mainResponse = await fetch("https://replicate.com/robots.txt");
    if (mainResponse.ok) {
      const text = await mainResponse.text();
      console.log("âœ… Main site robots.txt:");
      console.log(text);
      console.log("\n");
    } else {
      console.log(`âŒ Could not fetch: ${mainResponse.status}\n`);
    }
  } catch (error) {
    console.error("âŒ Error fetching main robots.txt:", error);
  }

  try {
    // Check search API (if it has one)
    console.log("ðŸ“„ Checking search API robots.txt");
    const searchResponse = await fetch("https://replicate-search-prototype-production.replicate.workers.dev/robots.txt");
    if (searchResponse.ok) {
      const text = await searchResponse.text();
      console.log("âœ… Search API robots.txt:");
      console.log(text);
    } else {
      console.log(`â„¹ï¸  No robots.txt for search API (${searchResponse.status} - this is normal)\n`);
    }
  } catch (error) {
    console.log("â„¹ï¸  Search API doesn't have robots.txt (this is normal)\n");
  }
}

async function checkRateLimits() {
  console.log("âš¡ Rate Limit Information:\n");
  console.log("Based on Replicate API documentation:");
  console.log("  â€¢ Create Prediction Requests: 600 requests/minute");
  console.log("  â€¢ All Other Endpoints: 3,000 requests/minute");
  console.log("  â€¢ Returns 429 status code when throttled\n");

  console.log("ðŸ“Š Current Scraper Rate Limiting:");
  console.log("  â€¢ Delay between model detail requests: 200ms");
  console.log("  â€¢ Requests per second: ~5 (300/minute)");
  console.log("  â€¢ Per model: 2 requests (schema + page)");
  console.log("  â€¢ For 50 models: ~100 requests in ~20 seconds");
  console.log("  â€¢ Well within limits âœ…\n");

  console.log("ðŸ’¡ Recommendations:");
  console.log("  â€¢ Current 200ms delay is conservative and safe");
  console.log("  â€¢ Could reduce to 100ms if needed (600 req/min)");
  console.log("  â€¢ Add exponential backoff on 429 errors");
  console.log("  â€¢ Respect robots.txt directives\n");
}

async function main() {
  await checkRobotsTxt();
  await checkRateLimits();
}

if (require.main === module) {
  main()
    .then(() => process.exit(0))
    .catch((error) => {
      console.error("Error:", error);
      process.exit(1);
    });
}

export {checkRobotsTxt, checkRateLimits};

