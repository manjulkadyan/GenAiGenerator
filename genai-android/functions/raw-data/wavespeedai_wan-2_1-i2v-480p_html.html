

<!DOCTYPE html>
<html lang="en"
      class="">

  <head>
    <meta charset="utf-8" />
    <title>
      
  
    Wan 2.1 image to video (480p)
  

    </title>

    
      
      <meta name="viewport"
            content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    

    <link id="favicon-ico"
          rel="icon"
          href="https://d31rfu1d3w8e4q.cloudfront.net/static/favicon.121ea3afd763.ico"
          sizes="any" />
    <link id="favicon-png"
          rel="icon"
          href="https://d31rfu1d3w8e4q.cloudfront.net/static/favicon.fdf5ef8729cc.png"
          type="image/png" />
    <link rel="mask-icon"
          href="https://d31rfu1d3w8e4q.cloudfront.net/static/safari-pinned-tab.4c32b8e091a9.svg"
          color="#FFFFFF" />
    <link rel="apple-touch-icon"
          sizes="180x180"
          href="https://d31rfu1d3w8e4q.cloudfront.net/static/apple-touch-icon.39c0aa0659e3.png" />

    
  <script nonce="xDxDFPBbzG01/nqc+Xuh7A==">
    /* beautify ignore:start */
    window.dataLayer = window.dataLayer || [];
    
    
    dataLayer.push({
      'event': 'user_anonymous',
      'user_type': 'anonymous',
      
      'anonymous_session_id': '5044a4f8-7811-4a90-83dd-d1fd1a5c2179'
      
    });
    
    /* beautify ignore:end */
  </script>
  <script nonce="xDxDFPBbzG01/nqc+Xuh7A==">
    (function(w, d, s, l, i) {
      w[l] = w[l] || [];
      w[l].push({
        'gtm.start': new Date().getTime(),
        event: 'gtm.js'
      });
      var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s),
        dl = l != 'dataLayer' ? '&l=' + l : '';
      j.async = true;
      j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
      f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-KZDCFZR9');
  </script>



    
    

    <link  rel="stylesheet" href="https://d31rfu1d3w8e4q.cloudfront.net/static/dist/index-BxwK8EBg.css" />
<script type="module" crossorigin="" src="https://d31rfu1d3w8e4q.cloudfront.net/static/dist/index-BK0wCkVE.js"></script>

    <link rel="stylesheet"
          href="https://d31rfu1d3w8e4q.cloudfront.net/static/dist/indexCss-D5iwNvwU.css" />

    <link rel="alternate"
          type="application/rss+xml"
          title="Blog (RSS)"
          href="https://replicate.com/blog/rss" />
    <link rel="alternate"
          type="application/atom+xml"
          title="Blog (Atom)"
          href="https://replicate.com/blog/atom" />
    <link rel="alternate"
          type="application/rss+xml"
          title="Changelog (RSS)"
          href="https://replicate.com/changelog/rss" />
    <link rel="alternate"
          type="application/atom+xml"
          title="Changelog (Atom)"
          href="https://replicate.com/changelog/atom" />
    <link rel="alternate"
          type="application/rss+xml"
          title="Status (RSS)"
          href="https://replicatestatus.com/feed" />

    
      <link rel="dns-prefetch"
            href="https://replicate.delivery" />
    
      <link rel="dns-prefetch"
            href="https://tjzk.replicate.delivery" />
    

    

    <link rel="canonical"
          href="https://replicate.com/wavespeedai/wan-2.1-i2v-480p" />

    
  
  
    
  

  <meta name="twitter:card"
        content="summary_large_image" />


<meta name="twitter:site"
      content="@replicate" />


  <meta name="twitter:image"
        content="https://og-api.replicateassets.com/api/models/wavespeedai/wan-2.1-i2v-480p" />
  <meta property="og:image"
        content="https://og-api.replicateassets.com/api/models/wavespeedai/wan-2.1-i2v-480p" />




  <meta name="twitter:title"
        content="Wan 2.1 image to video (480p)" />
  <meta name="twitter:description"
        content="Accelerated inference for Wan 2.1 14B image to video, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation." />
  <meta property="og:image"
        content="https://og-api.replicateassets.com/api/models/wavespeedai/wan-2.1-i2v-480p" />
  <meta property="twitter:image"
        content="https://og-api.replicateassets.com/api/models/wavespeedai/wan-2.1-i2v-480p" />

  

  
    <meta name="description"
          content="Accelerated inference for Wan 2.1 14B image to video, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation." />
  


    <meta name="sentry-dsn-js"
          content="https://3dc017e574684610bbc7fd3b5519a4e8@o255771.ingest.sentry.io/5909364" />
    
    
      <meta name="anonymous-id"
            content="5044a4f8-7811-4a90-83dd-d1fd1a5c2179" />
    

    
      <script nonce="xDxDFPBbzG01/nqc+Xuh7A==">
        const prefersDarkScheme = window.matchMedia('(prefers-color-scheme: dark)').matches;

        if (prefersDarkScheme) {
          document.documentElement.classList.add("dark");
        } else {
          document.documentElement.classList.add("light");
        }
      </script>
    

    
  </head>

  

  <body class="font-sans overflow-y-scroll antialiased flex min-h-screen flex-col">
    
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KZDCFZR9"
        height="0"
        width="0"
        style="display:none;
               visibility:hidden"></iframe></noscript>


    

      

      
        

<div class="h-[var(--header-height)] mb-6 no-focus">
  
    <script id="react-component-props-bcd3a45e-0a29-4409-98a0-517aad19f38b" type="application/json">{"activePath": "/wavespeedai/wan-2.1-i2v-480p", "isAuthenticated": false, "theme": "", "__flags": {"show-open-ai-api-instructions": false, "show-pylon-widget": false, "assign-support-tickets-to-ai": false}}</script>

<div data-component="Navigation"
     data-props="react-component-props-bcd3a45e-0a29-4409-98a0-517aad19f38b">
  
</div>

  
</div>

        



      

      
      

      
      

      

      <main class="layout-main flex-1">
        

        
          

  
  
  
    
      

    
      
    

    

    
      

<header class="space-y-4 pb-10 lg:pb-4"
        aria-label="wavespeedai/wan-2.1-i2v-480p">

  

<div class="flex gap-8 gap-y-4 w-full flex-wrap justify-between items-center">
  <div class="space-y-4">
    <div class="flex-wrap flex flex-col gap-1">

      <div class="flex gap-2 sm:gap-3 w-full">

        <h3 aria-label="wavespeedai/wan-2.1-i2v-480p"
            class="sr-only">
          wavespeedai/wan-2.1-i2v-480p
        </h3>

        <div translate="no"
             aria-hidden="true"
             class="flex relative items-center gap-1 flex-1 flex-wrap">
          <div class="flex items-center gap-3 whitespace-nowrap">
            
              


  <img class="avatar size-9 flex-shrink-0"
       src="https://tjzk.replicate.delivery/models_organizations_avatar/849379ed-24d5-4c40-87d0-dfa558ad2b17/ekC5W2Nx_400x400.jpg"
       alt=""
       role="presentation"
       onerror="this.onerror=null; this.src='https://d31rfu1d3w8e4q.cloudfront.net/static/placeholder-avatar-organization.ff98795474e8.svg'" />


            
            <div class="text-r8-gray-11 text-lg font-heading">
              
                <a href="https://replicate.com/wavespeedai">wavespeedai</a>
              
            </div>
            <div class="text-r8-gray-11 text-lg font-heading">
              /
            </div>
          </div>
          <div>
            <span class="text-lg font-heading">
              wan-2.1-i2v-480p
            </span>
            <span class="[&>div]:inline">
              
                <script id="react-component-props-2a660f0d-4e9e-499f-93f5-eb10bbb15fab" type="application/json">{"identifier": "wavespeedai/wan-2.1-i2v-480p", "__flags": {"show-open-ai-api-instructions": false, "show-pylon-widget": false, "assign-support-tickets-to-ai": false}}</script>

<div data-component="CopyIdentifierButton"
     data-props="react-component-props-2a660f0d-4e9e-499f-93f5-eb10bbb15fab">
  
</div>

              
            </span>
          </div>
        </div>
      </div>

      

    </div>
  </div>

  <div class="relative flex flex-wrap gap-2 md:justify-end w-full md:w-auto">

    

    

    <div>
      <script id="react-component-props-5d0cbe34-a383-492c-8012-5fdacc20691f" type="application/json">{"model": {"cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/75f0346d-ec4c-4078-bb40-6705578c0d21/replicate-prediction-br080xq9.webp", "description": "Accelerated inference for Wan 2.1 14B image to video, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation.", "hardware": "CPU", "latest_version": {"id": "70cc41f08f08a92133c0446992f846d86959f9eb7d7733d6a7a15b08062ef3cc"}, "name": "wan-2.1-i2v-480p", "owner": "wavespeedai", "url": "https://replicate.com/wavespeedai/wan-2.1-i2v-480p", "visibility": "public", "_extras": {"name": "wavespeedai/wan-2.1-i2v-480p", "is_official": true, "is_pipeline": false}}, "__flags": {"show-open-ai-api-instructions": false, "show-pylon-widget": false, "assign-support-tickets-to-ai": false}}</script>

<div data-component="ModelDetailButton"
     data-props="react-component-props-5d0cbe34-a383-492c-8012-5fdacc20691f">
  
</div>

    </div>
  </div>
</div>


  



<div class="flex flex-col gap-2 w-full">
  
    <div class="flex gap-4 flex-col md:flex-row items-start">
      
        <p class="max-w-3xl text-r8-lg [overflow-wrap:anywhere] text-pretty">
          
            Accelerated inference for Wan 2.1 14B image to video, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation.
            
          
        </p>
      
    </div>
  

  
</div>

<div class="w-full">
  <div class="space-y-4 @container">

    <div class="gap-y-2 items-start @xl:items-center grid @xl:flex @xl:flex-wrap @xl:flex-row @xs:grid-cols-2 gap-x-2 @xl:gap-x-6">

      
        <div class="flex items-center">
          <script id="react-component-props-16723ddb-452b-44f8-853b-faed72b055fd" type="application/json">{"initialStatus": "online", "model": {"cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/75f0346d-ec4c-4078-bb40-6705578c0d21/replicate-prediction-br080xq9.webp", "description": "Accelerated inference for Wan 2.1 14B image to video, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation.", "hardware": "CPU", "latest_version": {"id": "70cc41f08f08a92133c0446992f846d86959f9eb7d7733d6a7a15b08062ef3cc"}, "name": "wan-2.1-i2v-480p", "owner": "wavespeedai", "url": "https://replicate.com/wavespeedai/wan-2.1-i2v-480p", "visibility": "public", "_extras": {"name": "wavespeedai/wan-2.1-i2v-480p", "is_official": true, "is_pipeline": false}}, "isOfficialModel": "", "__flags": {"show-open-ai-api-instructions": false, "show-pylon-widget": false, "assign-support-tickets-to-ai": false}}</script>

  <div data-react-placeholder="ModelStatusIndicator">
    <div class="flex items-center">
  <div class="rounded-full bg-r8-gray-3 animate-pulse w-[64px] h-[29px]">
  </div>
</div>

  </div>

<div data-component="ModelStatusIndicator"
     data-props="react-component-props-16723ddb-452b-44f8-853b-faed72b055fd">
  
</div>

        </div>
      

      <div class="flex items-start gap-2">
        
          <span class="flex-shrink-0 -mt-0.5">
            <svg class="icon"
     fill="currentColor"
     xmlns="http://www.w3.org/2000/svg"
     viewBox="0 0 256 256">
  <rect width="256" height="256" fill="none" />
  <path d="M54.46,201.54c-9.2-9.2-3.1-28.53-7.78-39.85C41.82,150,24,140.5,24,128s17.82-22,22.68-33.69C51.36,83,45.26,63.66,54.46,54.46S83,51.36,94.31,46.68C106.05,41.82,115.5,24,128,24S150,41.82,161.69,46.68c11.32,4.68,30.65-1.42,39.85,7.78s3.1,28.53,7.78,39.85C214.18,106.05,232,115.5,232,128S214.18,150,209.32,161.69c-4.68,11.32,1.42,30.65-7.78,39.85s-28.53,3.1-39.85,7.78C150,214.18,140.5,232,128,232s-22-17.82-33.69-22.68C83,204.64,63.66,210.74,54.46,201.54Z" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="16" />
  <polyline points="88 136 112 160 168 104" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="16" />
</svg>

          </span>
          <span class="text-r8-sm"><script id="react-component-props-fa014361-254c-44f0-ae58-0a4de7bb24a4" type="application/json">{"anchorText": "Official", "anchorHref": "https://replicate.com/docs/topics/models/official-models", "tooltipText": "Official models are always on, maintained, and have predictable pricing.", "__flags": {"show-open-ai-api-instructions": false, "show-pylon-widget": false, "assign-support-tickets-to-ai": false}}</script>

<div data-component="TextTooltip"
     data-props="react-component-props-fa014361-254c-44f0-ae58-0a4de7bb24a4">
  
</div>
</span>
        
      </div>

      
        <div class="flex items-start gap-2">
          <span class="flex-shrink-0 -mt-0.5">
            
<svg class="icon"
     xmlns="http://www.w3.org/2000/svg"
     viewBox="0 0 24 24"
     width="24"
     height="24">
  <path fill="currentColor" fill-rule="evenodd" d="M20.322.75a10.75 10.75 0 00-7.373 2.926l-1.304 1.23A23.743 23.743 0 0010.103 6.5H5.066a1.75 1.75 0 00-1.5.85l-2.71 4.514a.75.75 0 00.49 1.12l4.571.963c.039.049.082.096.129.14L8.04 15.96l1.872 1.994c.044.047.091.09.14.129l.963 4.572a.75.75 0 001.12.488l4.514-2.709a1.75 1.75 0 00.85-1.5v-5.038a23.741 23.741 0 001.596-1.542l1.228-1.304a10.75 10.75 0 002.925-7.374V2.499A1.75 1.75 0 0021.498.75h-1.177zM16 15.112c-.333.248-.672.487-1.018.718l-3.393 2.262.678 3.223 3.612-2.167a.25.25 0 00.121-.214v-3.822zm-10.092-2.7L8.17 9.017c.23-.346.47-.685.717-1.017H5.066a.25.25 0 00-.214.121l-2.167 3.612 3.223.679zm8.07-7.644a9.25 9.25 0 016.344-2.518h1.177a.25.25 0 01.25.25v1.176a9.25 9.25 0 01-2.517 6.346l-1.228 1.303a22.248 22.248 0 01-3.854 3.257l-3.288 2.192-1.743-1.858a.764.764 0 00-.034-.034l-1.859-1.744 2.193-3.29a22.248 22.248 0 013.255-3.851l1.304-1.23zM17.5 8a1.5 1.5 0 11-3 0 1.5 1.5 0 013 0zm-11 13c.9-.9.9-2.6 0-3.5-.9-.9-2.6-.9-3.5 0-1.209 1.209-1.445 3.901-1.49 4.743a.232.232 0 00.247.247c.842-.045 3.534-.281 4.743-1.49z">
  </path>
</svg>

          </span>
          <span class="text-r8-sm whitespace-nowrap">426.3K
            runs
          </span>
        </div>

        
          <div class="[&>div]:flex">
            
            <script id="react-component-props-9ed4ae02-9f2f-4ead-bd90-cf0faae937ae" type="application/json">{"version": {"id": "c166c026d33405455f2c8da230f5e4bf09efac09a539af0f494a13ed5aa6929d", "created_at": "2025-11-07T13:47:47.823379Z", "_extras": {"arch": "cpu", "dereferenced_openapi_schema": {"info": {"title": "Cog", "version": "0.1.0"}, "paths": {"/": {"get": {"summary": "Root", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Root  Get"}}}, "description": "Successful Response"}}, "operationId": "root__get"}}, "/shutdown": {"post": {"summary": "Start Shutdown", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Start Shutdown Shutdown Post"}}}, "description": "Successful Response"}}, "operationId": "start_shutdown_shutdown_post"}}, "/predictions": {"post": {"summary": "Predict", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "nullable": true, "description": "Random seed. Set for reproducible generation"}, "image": {"type": "string", "title": "Image", "format": "uri", "description": "Image for use as the initial frame of the video."}, "prompt": {"type": "string", "title": "Prompt", "description": "Text prompt for image generation"}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Balanced", "x-order": 4}, "lora_scale": {"type": "number", "title": "Lora Scale", "default": 1, "maximum": 4, "minimum": 0, "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. You may still need to experiment to find the best value for your particular lora."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Aspect ratio of the output video.", "default": "16:9", "x-order": 2}, "lora_weights": {"type": "string", "title": "Lora Weights", "nullable": true, "description": "Load LoRA weights. Supports HuggingFace URLs in the format huggingface.co/\u003Cowner\u003E/\u003Cmodel-name\u003E, CivitAI URLs in the format civitai.com/models/\u003Cid\u003E[/\u003Cmodel-name\u003E], or arbitrary .safetensors URLs from the Internet."}, "sample_shift": {"type": "integer", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 0, "description": "Flow shift parameter for video generation"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "description": "Number of inference steps"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "default": "", "description": "Negative prompt to avoid certain elements"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 1, "description": "Guidance scale for generation"}, "disable_safety_checker": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "description": "Disable safety checker for generated videos"}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model", "operationId": "predict_predictions_post", "requestBody": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "nullable": true, "description": "Random seed. Set for reproducible generation"}, "image": {"type": "string", "title": "Image", "format": "uri", "description": "Image for use as the initial frame of the video."}, "prompt": {"type": "string", "title": "Prompt", "description": "Text prompt for image generation"}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Balanced", "x-order": 4}, "lora_scale": {"type": "number", "title": "Lora Scale", "default": 1, "maximum": 4, "minimum": 0, "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. You may still need to experiment to find the best value for your particular lora."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Aspect ratio of the output video.", "default": "16:9", "x-order": 2}, "lora_weights": {"type": "string", "title": "Lora Weights", "nullable": true, "description": "Load LoRA weights. Supports HuggingFace URLs in the format huggingface.co/\u003Cowner\u003E/\u003Cmodel-name\u003E, CivitAI URLs in the format civitai.com/models/\u003Cid\u003E[/\u003Cmodel-name\u003E], or arbitrary .safetensors URLs from the Internet."}, "sample_shift": {"type": "integer", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 0, "description": "Flow shift parameter for video generation"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "description": "Number of inference steps"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "default": "", "description": "Negative prompt to avoid certain elements"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 1, "description": "Guidance scale for generation"}, "disable_safety_checker": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "description": "Disable safety checker for generated videos"}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}}}}}}, "/health-check": {"get": {"summary": "Healthcheck", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Healthcheck Health Check Get"}}}, "description": "Successful Response"}}, "operationId": "healthcheck_health_check_get"}}, "/predictions/{prediction_id}": {"put": {"summary": "Predict Idempotent", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "nullable": true, "description": "Random seed. Set for reproducible generation"}, "image": {"type": "string", "title": "Image", "format": "uri", "description": "Image for use as the initial frame of the video."}, "prompt": {"type": "string", "title": "Prompt", "description": "Text prompt for image generation"}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Balanced", "x-order": 4}, "lora_scale": {"type": "number", "title": "Lora Scale", "default": 1, "maximum": 4, "minimum": 0, "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. You may still need to experiment to find the best value for your particular lora."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Aspect ratio of the output video.", "default": "16:9", "x-order": 2}, "lora_weights": {"type": "string", "title": "Lora Weights", "nullable": true, "description": "Load LoRA weights. Supports HuggingFace URLs in the format huggingface.co/\u003Cowner\u003E/\u003Cmodel-name\u003E, CivitAI URLs in the format civitai.com/models/\u003Cid\u003E[/\u003Cmodel-name\u003E], or arbitrary .safetensors URLs from the Internet."}, "sample_shift": {"type": "integer", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 0, "description": "Flow shift parameter for video generation"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "description": "Number of inference steps"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "default": "", "description": "Negative prompt to avoid certain elements"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 1, "description": "Guidance scale for generation"}, "disable_safety_checker": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "description": "Disable safety checker for generated videos"}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}, {"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model (idempotent creation).", "operationId": "predict_idempotent_predictions__prediction_id__put", "requestBody": {"content": {"application/json": {"schema": {"allOf": [{"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "nullable": true, "description": "Random seed. Set for reproducible generation"}, "image": {"type": "string", "title": "Image", "format": "uri", "description": "Image for use as the initial frame of the video."}, "prompt": {"type": "string", "title": "Prompt", "description": "Text prompt for image generation"}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Balanced", "x-order": 4}, "lora_scale": {"type": "number", "title": "Lora Scale", "default": 1, "maximum": 4, "minimum": 0, "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. You may still need to experiment to find the best value for your particular lora."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Aspect ratio of the output video.", "default": "16:9", "x-order": 2}, "lora_weights": {"type": "string", "title": "Lora Weights", "nullable": true, "description": "Load LoRA weights. Supports HuggingFace URLs in the format huggingface.co/\u003Cowner\u003E/\u003Cmodel-name\u003E, CivitAI URLs in the format civitai.com/models/\u003Cid\u003E[/\u003Cmodel-name\u003E], or arbitrary .safetensors URLs from the Internet."}, "sample_shift": {"type": "integer", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 0, "description": "Flow shift parameter for video generation"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "description": "Number of inference steps"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "default": "", "description": "Negative prompt to avoid certain elements"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 1, "description": "Guidance scale for generation"}, "disable_safety_checker": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "description": "Disable safety checker for generated videos"}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}], "title": "Prediction Request"}}}, "required": true}}}, "/predictions/{prediction_id}/cancel": {"post": {"summary": "Cancel", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Cancel Predictions  Prediction Id  Cancel Post"}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}], "description": "Cancel a running prediction", "operationId": "cancel_predictions__prediction_id__cancel_post"}}}, "openapi": "3.0.2", "components": {"schemas": {"Input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "nullable": true, "description": "Random seed. Set for reproducible generation"}, "image": {"type": "string", "title": "Image", "format": "uri", "description": "Image for use as the initial frame of the video."}, "prompt": {"type": "string", "title": "Prompt", "description": "Text prompt for image generation"}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Balanced", "x-order": 4}, "lora_scale": {"type": "number", "title": "Lora Scale", "default": 1, "maximum": 4, "minimum": 0, "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. You may still need to experiment to find the best value for your particular lora."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Aspect ratio of the output video.", "default": "16:9", "x-order": 2}, "lora_weights": {"type": "string", "title": "Lora Weights", "nullable": true, "description": "Load LoRA weights. Supports HuggingFace URLs in the format huggingface.co/\u003Cowner\u003E/\u003Cmodel-name\u003E, CivitAI URLs in the format civitai.com/models/\u003Cid\u003E[/\u003Cmodel-name\u003E], or arbitrary .safetensors URLs from the Internet."}, "sample_shift": {"type": "integer", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 0, "description": "Flow shift parameter for video generation"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "description": "Number of inference steps"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "default": "", "description": "Negative prompt to avoid certain elements"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 1, "description": "Guidance scale for generation"}, "disable_safety_checker": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "description": "Disable safety checker for generated videos"}}}, "Output": {"type": "string", "title": "Output", "format": "uri"}, "Status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "An enumeration."}, "WebhookEvent": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "An enumeration."}, "ValidationError": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "PredictionRequest": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "nullable": true, "description": "Random seed. Set for reproducible generation"}, "image": {"type": "string", "title": "Image", "format": "uri", "description": "Image for use as the initial frame of the video."}, "prompt": {"type": "string", "title": "Prompt", "description": "Text prompt for image generation"}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Balanced", "x-order": 4}, "lora_scale": {"type": "number", "title": "Lora Scale", "default": 1, "maximum": 4, "minimum": 0, "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. You may still need to experiment to find the best value for your particular lora."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Aspect ratio of the output video.", "default": "16:9", "x-order": 2}, "lora_weights": {"type": "string", "title": "Lora Weights", "nullable": true, "description": "Load LoRA weights. Supports HuggingFace URLs in the format huggingface.co/\u003Cowner\u003E/\u003Cmodel-name\u003E, CivitAI URLs in the format civitai.com/models/\u003Cid\u003E[/\u003Cmodel-name\u003E], or arbitrary .safetensors URLs from the Internet."}, "sample_shift": {"type": "integer", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 0, "description": "Flow shift parameter for video generation"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "description": "Number of inference steps"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "default": "", "description": "Negative prompt to avoid certain elements"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 1, "description": "Guidance scale for generation"}, "disable_safety_checker": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "description": "Disable safety checker for generated videos"}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}, "PredictionResponse": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "nullable": true, "description": "Random seed. Set for reproducible generation"}, "image": {"type": "string", "title": "Image", "format": "uri", "description": "Image for use as the initial frame of the video."}, "prompt": {"type": "string", "title": "Prompt", "description": "Text prompt for image generation"}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Balanced", "x-order": 4}, "lora_scale": {"type": "number", "title": "Lora Scale", "default": 1, "maximum": 4, "minimum": 0, "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. You may still need to experiment to find the best value for your particular lora."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Aspect ratio of the output video.", "default": "16:9", "x-order": 2}, "lora_weights": {"type": "string", "title": "Lora Weights", "nullable": true, "description": "Load LoRA weights. Supports HuggingFace URLs in the format huggingface.co/\u003Cowner\u003E/\u003Cmodel-name\u003E, CivitAI URLs in the format civitai.com/models/\u003Cid\u003E[/\u003Cmodel-name\u003E], or arbitrary .safetensors URLs from the Internet."}, "sample_shift": {"type": "integer", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 0, "description": "Flow shift parameter for video generation"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "description": "Number of inference steps"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "default": "", "description": "Negative prompt to avoid certain elements"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 1, "description": "Guidance scale for generation"}, "disable_safety_checker": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "description": "Disable safety checker for generated videos"}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}, "HTTPValidationError": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}}, "disabled_for_predictions": false, "disabled_for_trainings": false, "model": {"cover_image_url": "https://replicate.delivery/xezq/ZyWZxK0QxY4YPlIKx4MtoaRspem81q7rMaacQEj3vqyyuqJKA/output.mp4", "description": null, "hardware": null, "latest_version": {"id": "c166c026d33405455f2c8da230f5e4bf09efac09a539af0f494a13ed5aa6929d"}, "name": "wavespeed-wan-2.1-i2v-480p-internal-model", "owner": "replicate", "url": "https://replicate.com/replicate/wavespeed-wan-2.1-i2v-480p-internal-model", "visibility": "private", "_extras": {"name": "replicate/wavespeed-wan-2.1-i2v-480p-internal-model", "is_official": false, "is_pipeline": false}}, "name": "replicate/wavespeed-wan-2.1-i2v-480p-internal-model:c166c026", "release_notes": null, "short_id": "c166c026", "url": "https://replicate.com/replicate/wavespeed-wan-2.1-i2v-480p-internal-model/versions/c166c026d33405455f2c8da230f5e4bf09efac09a539af0f494a13ed5aa6929d"}}, "hardware": "CPU", "billingConfig": {"current_description": null, "current_tiers": [{"criteria": [], "description": null, "prices": [{"description": "or around 11 seconds for $1", "metric": "video_output_duration_seconds", "metric_display": "second of output video", "price": "$0.09", "title": "per second of output video", "type": "per-unit"}], "title": null}]}, "price": "$0.0001 per second", "p50price": "$0.0053", "model": {"cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/75f0346d-ec4c-4078-bb40-6705578c0d21/replicate-prediction-br080xq9.webp", "description": "Accelerated inference for Wan 2.1 14B image to video, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation.", "hardware": "CPU", "latest_version": {"id": "70cc41f08f08a92133c0446992f846d86959f9eb7d7733d6a7a15b08062ef3cc"}, "name": "wan-2.1-i2v-480p", "owner": "wavespeedai", "url": "https://replicate.com/wavespeedai/wan-2.1-i2v-480p", "visibility": "public", "_extras": {"name": "wavespeedai/wan-2.1-i2v-480p", "is_official": true, "is_pipeline": false}}, "__flags": {"show-open-ai-api-instructions": false, "show-pylon-widget": false, "assign-support-tickets-to-ai": false}}</script>

<div data-component="ModelPricePopover"
     data-props="react-component-props-9ed4ae02-9f2f-4ead-bd90-cf0faae937ae">
  
</div>

          </div>
        
      

      
        <div class="flex items-start gap-2">
          <i class="-mt-0.5">
            
<svg xmlns="http://www.w3.org/2000/svg"
     width="24"
     height="24"
     viewBox="0 0 24 24"
     fill="none"
     stroke="currentColor"
     stroke-width="2"
     stroke-linecap="round"
     stroke-linejoin="round"
     class="icon">
  <polyline points="20 6 9 17 4 12"></polyline>
</svg>

          </i>
          <div class="text-r8-sm">
            <script id="react-component-props-8cb6da71-a70b-4ee4-aa63-d154ab5ea089" type="application/json">{"anchorHref": "https://github.com/Wan-Video/Wan2.1/blob/main/LICENSE.txt", "anchorText": "Commercial use", "tooltipText": "Outputs from this model can be sold or used in paid products.", "__flags": {"show-open-ai-api-instructions": false, "show-pylon-widget": false, "assign-support-tickets-to-ai": false}}</script>

<div data-component="TextTooltip"
     data-props="react-component-props-8cb6da71-a70b-4ee4-aa63-d154ab5ea089">
  
</div>

          </div>
        </div>
      

      

        <div class="flex items-start gap-2">
          <i class="-mt-0.5">
            
<svg class="icon"
     xmlns="http://www.w3.org/2000/svg"
     width="24"
     height="24"
     viewBox="0 0 24 24"
     fill="none"
     stroke="currentColor"
     stroke-width="2"
     stroke-linecap="round"
     stroke-linejoin="round">
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0020 4.77 5.07 5.07 0 0019.91 1S18.73.65 16 2.48a13.38 13.38 0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 005 4.77a5.44 5.44 0 00-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 009 18.13V22">
  </path>
</svg>

          </i>
          <a href="https://github.com/Wan-Video/Wan2.1"
             target="_blank"
             class="text-r8-sm">
            GitHub
          </a>
        </div>
      

      

        <div class="flex items-start gap-2">
          <i class="-mt-0.5">
            
<svg xmlns="http://www.w3.org/2000/svg"
     width="24"
     height="24"
     viewBox="0 0 24 24"
     fill="none"
     stroke="currentColor"
     stroke-width="2"
     stroke-linecap="round"
     stroke-linejoin="round"
     class="icon">
  <circle cx="12" cy="5" r="3" />
  <path d="M6.5 8a2 2 0 0 0-1.905 1.46L2.1 18.5A2 2 0 0 0 4 21h16a2 2 0 0 0 1.925-2.54L19.4 9.5A2 2 0 0 0 17.48 8Z" />
</svg>

          </i>
          <a href="https://huggingface.co/Wan-AI/Wan2.1-T2V-14B"
             target="_blank"
             class="text-r8-sm">
            Weights
          </a>
        </div>
      

      

    </div>

    

  </div>
</div>


</header>

    
    
      
        <div class="border-b border-r8-gray-6">
          






<div class="r8-tabs r8-tabs--bordered r8-tabs--md top-px relative flex-wrap">
  
    <a href="/wavespeedai/wan-2.1-i2v-480p"
       aria-selected="true"
       class="r8-tabs__tab no-underline">
      <span class="r8-tabs__start-icon">
        <svg class="icon"
     xmlns="http://www.w3.org/2000/svg"
     width="24"
     height="24"
     viewBox="0 0 24 24"
     fill="none"
     stroke="currentColor"
     stroke-width="1.5"
     stroke-linecap="round"
     stroke-linejoin="round">
  <polygon points="5 3 19 12 5 21 5 3"></polygon>

</svg>

      </span>
      <span>Playground</span>
    </a>
  

  
    
      <a href="/wavespeedai/wan-2.1-i2v-480p/api"
         
         class="r8-tabs__tab no-underline">

        <span class="r8-tabs__start-icon">
          
<svg class="icon"
     xmlns="http://www.w3.org/2000/svg"
     viewBox="0 0 24 24"
     width="24"
     height="24">
  <path fill="currentColor" fill-rule="evenodd" d="M20.322.75a10.75 10.75 0 00-7.373 2.926l-1.304 1.23A23.743 23.743 0 0010.103 6.5H5.066a1.75 1.75 0 00-1.5.85l-2.71 4.514a.75.75 0 00.49 1.12l4.571.963c.039.049.082.096.129.14L8.04 15.96l1.872 1.994c.044.047.091.09.14.129l.963 4.572a.75.75 0 001.12.488l4.514-2.709a1.75 1.75 0 00.85-1.5v-5.038a23.741 23.741 0 001.596-1.542l1.228-1.304a10.75 10.75 0 002.925-7.374V2.499A1.75 1.75 0 0021.498.75h-1.177zM16 15.112c-.333.248-.672.487-1.018.718l-3.393 2.262.678 3.223 3.612-2.167a.25.25 0 00.121-.214v-3.822zm-10.092-2.7L8.17 9.017c.23-.346.47-.685.717-1.017H5.066a.25.25 0 00-.214.121l-2.167 3.612 3.223.679zm8.07-7.644a9.25 9.25 0 016.344-2.518h1.177a.25.25 0 01.25.25v1.176a9.25 9.25 0 01-2.517 6.346l-1.228 1.303a22.248 22.248 0 01-3.854 3.257l-3.288 2.192-1.743-1.858a.764.764 0 00-.034-.034l-1.859-1.744 2.193-3.29a22.248 22.248 0 013.255-3.851l1.304-1.23zM17.5 8a1.5 1.5 0 11-3 0 1.5 1.5 0 013 0zm-11 13c.9-.9.9-2.6 0-3.5-.9-.9-2.6-.9-3.5 0-1.209 1.209-1.445 3.901-1.49 4.743a.232.232 0 00.247.247c.842-.045 3.534-.281 4.743-1.49z">
  </path>
</svg>

        </span>
        <span>API</span>
      </a>
    
  

  
    <a href="/wavespeedai/wan-2.1-i2v-480p/examples"
       
       class="r8-tabs__tab no-underline">
      <span class="r8-tabs__start-icon">
        <svg class="icon"
     xmlns="http://www.w3.org/2000/svg"
     width="24"
     height="24"
     viewBox="0 0 24 24"
     fill="none"
     stroke="currentColor"
     stroke-width="1.5"
     stroke-linecap="round"
     stroke-linejoin="round">
  <rect x="3" y="3" width="18" height="18" rx="2" ry="2"></rect>
  <polyline points="11 3 11 11 14 8 17 11 17 3"></polyline>
</svg>

      </span>
      <span>Examples</span>
    </a>
  

  

  <a href="/wavespeedai/wan-2.1-i2v-480p/readme"
     
     class="r8-tabs__tab no-underline">
    <span class="r8-tabs__start-icon">
      
<svg xmlns="http://www.w3.org/2000/svg"
     width="24"
     height="24"
     viewBox="0 0 24 24"
     fill="none"
     stroke="currentColor"
     stroke-width="1.5"
     stroke-linecap="round"
     stroke-linejoin="round"
     class="icon">
  <path d="M14.5 2H6a2 2 0 00-2 2v16a2 2 0 002 2h12a2 2 0 002-2V7.5L14.5 2z">
  </path>
  <polyline points="14 2 14 8 20 8"></polyline>
  <line x1="16" y1="13" x2="8" y2="13"></line>
  <line x1="16" y1="17" x2="8" y2="17"></line>
  <line x1="10" y1="9" x2="8" y2="9"></line>
</svg>

    </span>
    <span>README</span>
  </a>

  
    
  

  

  

  
</div>

        </div>
      
    

    

  
    
  


  
    <div class="model-content mt-lh">
      
  
    

<div class="mb-2lh">
  
  
  
    <script id="react-component-props-ec08bc0f-f57c-402f-8684-3e6b70ca5b1f" type="application/json">{"initialPrediction": {"completed_at": "2025-03-03T11:10:07Z", "created_at": "2025-03-03T11:09:28.431000Z", "data_removed": false, "error": "", "id": "5kgmyvakxxrme0cnbesb198s0r", "input": {"image": "https://replicate.delivery/pbxt/MZZyui7brAbh1d2AsyPtgPIByUwzSv6Uou8objC7zXEjLySc/1a8nt7yw5drm80cn05r89mjce0.png", "prompt": "A woman is talking", "max_area": "832x480", "fast_mode": "Balanced", "num_frames": 81, "sample_shift": 3, "sample_steps": 30, "frames_per_second": 16, "sample_guide_scale": 5}, "logs": "Moderating content...\r\nImage size: 8.2KB\r\nModeration complete in 0.97sec\r\nUsing seed: 1765621119\r\n  0%|          | 0/30 [00:00\u003C?, ?it/s]\r\n  0%|          | 0/30 [00:00\u003C?, ?it/s]\r\n  0%|          | 0/30 [00:00\u003C?, ?it/s]\r\n  0%|          | 0/30 [00:00\u003C?, ?it/s]\r\n  0%|          | 0/30 [00:00\u003C?, ?it/s]\r\n  0%|          | 0/30 [00:00\u003C?, ?it/s]\r\n  0%|          | 0/30 [00:00\u003C?, ?it/s]\r\n  0%|          | 0/30 [00:00\u003C?, ?it/s]\r\n3%|\u258e         | 1/30 [00:01\u003C00:44,  1.54s/it]\r\n3%|\u258e         | 1/30 [00:01\u003C00:44,  1.55s/it]\r\n3%|\u258e         | 1/30 [00:01\u003C00:44,  1.55s/it]\r\n3%|\u258e         | 1/30 [00:01\u003C00:44,  1.54s/it]\r\n  3%|\u258e         | 1/30 [00:01\u003C00:44,  1.55s/it]\r\n3%|\u258e         | 1/30 [00:01\u003C00:45,  1.55s/it]\r\n  3%|\u258e         | 1/30 [00:01\u003C00:45,  1.57s/it]\r\n  3%|\u258e         | 1/30 [00:01\u003C00:44,  1.55s/it]\r\n7%|\u258b         | 2/30 [00:03\u003C00:43,  1.55s/it]\r\n7%|\u258b         | 2/30 [00:03\u003C00:43,  1.55s/it]\r\n7%|\u258b         | 2/30 [00:03\u003C00:43,  1.55s/it]\r\n7%|\u258b         | 2/30 [00:03\u003C00:43,  1.56s/it]\r\n7%|\u258b         | 2/30 [00:03\u003C00:43,  1.57s/it]\r\n  7%|\u258b         | 2/30 [00:03\u003C00:43,  1.55s/it]\r\n  7%|\u258b         | 2/30 [00:03\u003C00:43,  1.56s/it]\r\n  7%|\u258b         | 2/30 [00:03\u003C00:43,  1.55s/it]\r\n10%|\u2588         | 3/30 [00:04\u003C00:41,  1.55s/it]\r\n10%|\u2588         | 3/30 [00:04\u003C00:41,  1.56s/it]\r\n10%|\u2588         | 3/30 [00:04\u003C00:41,  1.55s/it]\r\n10%|\u2588         | 3/30 [00:04\u003C00:42,  1.56s/it]\r\n10%|\u2588         | 3/30 [00:04\u003C00:41,  1.55s/it]\r\n10%|\u2588         | 3/30 [00:04\u003C00:42,  1.56s/it]\r\n 10%|\u2588         | 3/30 [00:04\u003C00:42,  1.56s/it]\r\n 10%|\u2588         | 3/30 [00:04\u003C00:41,  1.56s/it]\r\n13%|\u2588\u258e        | 4/30 [00:06\u003C00:40,  1.56s/it]\r\n13%|\u2588\u258e        | 4/30 [00:06\u003C00:40,  1.56s/it]\r\n13%|\u2588\u258e        | 4/30 [00:06\u003C00:40,  1.56s/it]\r\n13%|\u2588\u258e        | 4/30 [00:06\u003C00:40,  1.56s/it]\r\n13%|\u2588\u258e        | 4/30 [00:06\u003C00:40,  1.56s/it]\r\n13%|\u2588\u258e        | 4/30 [00:06\u003C00:40,  1.56s/it]\r\n 13%|\u2588\u258e        | 4/30 [00:06\u003C00:40,  1.56s/it]\r\n 13%|\u2588\u258e        | 4/30 [00:06\u003C00:40,  1.56s/it]\r\n17%|\u2588\u258b        | 5/30 [00:07\u003C00:38,  1.56s/it]\r\n17%|\u2588\u258b        | 5/30 [00:07\u003C00:38,  1.56s/it]\r\n17%|\u2588\u258b        | 5/30 [00:07\u003C00:38,  1.56s/it]\r\n17%|\u2588\u258b        | 5/30 [00:07\u003C00:38,  1.56s/it]\r\n 17%|\u2588\u258b        | 5/30 [00:07\u003C00:38,  1.56s/it]\r\n 17%|\u2588\u258b        | 5/30 [00:07\u003C00:39,  1.56s/it]\r\n 17%|\u2588\u258b        | 5/30 [00:07\u003C00:38,  1.56s/it]\r\n 17%|\u2588\u258b        | 5/30 [00:07\u003C00:38,  1.56s/it]\r\n23%|\u2588\u2588\u258e       | 7/30 [00:09\u003C00:27,  1.17s/it]\r\n23%|\u2588\u2588\u258e       | 7/30 [00:09\u003C00:27,  1.17s/it]\r\n23%|\u2588\u2588\u258e       | 7/30 [00:09\u003C00:27,  1.17s/it]\r\n 23%|\u2588\u2588\u258e       | 7/30 [00:09\u003C00:27,  1.17s/it]\r\n23%|\u2588\u2588\u258e       | 7/30 [00:09\u003C00:27,  1.18s/it]\r\n 23%|\u2588\u2588\u258e       | 7/30 [00:09\u003C00:27,  1.18s/it]\r\n 23%|\u2588\u2588\u258e       | 7/30 [00:09\u003C00:27,  1.17s/it]\r\n 23%|\u2588\u2588\u258e       | 7/30 [00:09\u003C00:27,  1.17s/it]\r\n30%|\u2588\u2588\u2588       | 9/30 [00:10\u003C00:21,  1.02s/it]\r\n30%|\u2588\u2588\u2588       | 9/30 [00:10\u003C00:21,  1.02s/it]\r\n30%|\u2588\u2588\u2588       | 9/30 [00:10\u003C00:21,  1.02s/it]\r\n 30%|\u2588\u2588\u2588       | 9/30 [00:10\u003C00:21,  1.02s/it]\r\n 30%|\u2588\u2588\u2588       | 9/30 [00:10\u003C00:21,  1.02s/it]\r\n30%|\u2588\u2588\u2588       | 9/30 [00:11\u003C00:21,  1.02s/it]\r\n 30%|\u2588\u2588\u2588       | 9/30 [00:11\u003C00:21,  1.02s/it]\r\n 30%|\u2588\u2588\u2588       | 9/30 [00:10\u003C00:21,  1.02s/it]\r\n37%|\u2588\u2588\u2588\u258b      | 11/30 [00:12\u003C00:17,  1.07it/s]\r\n37%|\u2588\u2588\u2588\u258b      | 11/30 [00:12\u003C00:17,  1.07it/s]\r\n37%|\u2588\u2588\u2588\u258b      | 11/30 [00:12\u003C00:17,  1.07it/s]\r\n37%|\u2588\u2588\u2588\u258b      | 11/30 [00:12\u003C00:17,  1.07it/s]\r\n37%|\u2588\u2588\u2588\u258b      | 11/30 [00:12\u003C00:17,  1.07it/s]\r\n37%|\u2588\u2588\u2588\u258b      | 11/30 [00:12\u003C00:17,  1.07it/s]\r\n37%|\u2588\u2588\u2588\u258b      | 11/30 [00:12\u003C00:17,  1.07it/s]\r\n 37%|\u2588\u2588\u2588\u258b      | 11/30 [00:12\u003C00:17,  1.07it/s]\r\n43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:14\u003C00:15,  1.12it/s]\r\n43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:14\u003C00:15,  1.12it/s]\r\n43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:14\u003C00:15,  1.12it/s]\r\n43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:14\u003C00:15,  1.12it/s]\r\n 43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:14\u003C00:15,  1.12it/s]\r\n43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:14\u003C00:15,  1.12it/s]\r\n 43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:14\u003C00:15,  1.12it/s]\r\n 43%|\u2588\u2588\u2588\u2588\u258e     | 13/30 [00:14\u003C00:15,  1.12it/s]\r\n50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:15\u003C00:12,  1.16it/s]\r\n50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:15\u003C00:12,  1.16it/s]\r\n50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:15\u003C00:12,  1.16it/s]\r\n50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:15\u003C00:12,  1.16it/s]\r\n50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:15\u003C00:12,  1.16it/s]\r\n50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:15\u003C00:12,  1.16it/s]\r\n50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:15\u003C00:12,  1.16it/s]\r\n 50%|\u2588\u2588\u2588\u2588\u2588     | 15/30 [00:15\u003C00:12,  1.16it/s]\r\n57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:17\u003C00:10,  1.19it/s]\r\n57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:17\u003C00:10,  1.19it/s]\r\n57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:17\u003C00:10,  1.19it/s]\r\n57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:17\u003C00:10,  1.19it/s]\r\n57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:17\u003C00:10,  1.19it/s]\r\n57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:17\u003C00:10,  1.19it/s]\r\n 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:17\u003C00:10,  1.19it/s]\r\n 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 17/30 [00:17\u003C00:10,  1.19it/s]\r\n63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:19\u003C00:09,  1.20it/s]\r\n63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:19\u003C00:09,  1.20it/s]\r\n63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:19\u003C00:09,  1.20it/s]\r\n63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:19\u003C00:09,  1.20it/s]\r\n63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:19\u003C00:09,  1.20it/s]\r\n63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:19\u003C00:09,  1.20it/s]\r\n 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:19\u003C00:09,  1.20it/s]\r\n 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 19/30 [00:19\u003C00:09,  1.20it/s]\r\n70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:20\u003C00:07,  1.22it/s]\r\n70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:20\u003C00:07,  1.22it/s]\r\n70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:20\u003C00:07,  1.22it/s]\r\n70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:20\u003C00:07,  1.22it/s]\r\n70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:20\u003C00:07,  1.22it/s]\r\n70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:20\u003C00:07,  1.22it/s]\r\n 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:20\u003C00:07,  1.22it/s]\r\n 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 21/30 [00:20\u003C00:07,  1.22it/s]\r\n77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:22\u003C00:05,  1.22it/s]\r\n77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:22\u003C00:05,  1.22it/s]\r\n77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:22\u003C00:05,  1.22it/s]\r\n77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:22\u003C00:05,  1.22it/s]\r\n77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:22\u003C00:05,  1.22it/s]\r\n77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:22\u003C00:05,  1.22it/s]\r\n 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:22\u003C00:05,  1.22it/s]\r\n 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 23/30 [00:22\u003C00:05,  1.22it/s]\r\n80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:23\u003C00:05,  1.05it/s]\r\n80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:23\u003C00:05,  1.05it/s]\r\n80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:23\u003C00:05,  1.05it/s]\r\n80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:23\u003C00:05,  1.05it/s]\r\n80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:23\u003C00:05,  1.05it/s]\r\n80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:23\u003C00:05,  1.05it/s]\r\n 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:23\u003C00:05,  1.05it/s]\r\n 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 24/30 [00:23\u003C00:05,  1.05it/s]\r\n83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [00:25\u003C00:05,  1.08s/it]\r\n83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [00:25\u003C00:05,  1.08s/it]\r\n83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [00:25\u003C00:05,  1.08s/it]\r\n83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [00:25\u003C00:05,  1.08s/it]\r\n83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [00:25\u003C00:05,  1.08s/it]\r\n83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [00:25\u003C00:05,  1.08s/it]\r\n83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [00:25\u003C00:05,  1.08s/it]\r\n 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 25/30 [00:25\u003C00:05,  1.08s/it]\r\n87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [00:26\u003C00:04,  1.18s/it]\r\n87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [00:26\u003C00:04,  1.18s/it]\r\n87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [00:26\u003C00:04,  1.18s/it]\r\n87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [00:26\u003C00:04,  1.18s/it]\r\n87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [00:26\u003C00:04,  1.18s/it]\r\n87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [00:26\u003C00:04,  1.18s/it]\r\n87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [00:26\u003C00:04,  1.18s/it]\r\n 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 26/30 [00:26\u003C00:04,  1.18s/it]\r\n90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [00:28\u003C00:03,  1.28s/it]\r\n90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [00:28\u003C00:03,  1.28s/it]\r\n90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [00:28\u003C00:03,  1.28s/it]\r\n90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [00:28\u003C00:03,  1.28s/it]\r\n90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [00:28\u003C00:03,  1.28s/it]\r\n90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [00:28\u003C00:03,  1.28s/it]\r\n 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [00:28\u003C00:03,  1.28s/it]\r\n 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 27/30 [00:28\u003C00:03,  1.28s/it]\r\n93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [00:30\u003C00:02,  1.35s/it]\r\n93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [00:30\u003C00:02,  1.35s/it]\r\n93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [00:30\u003C00:02,  1.35s/it]\r\n93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [00:30\u003C00:02,  1.35s/it]\r\n93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [00:30\u003C00:02,  1.35s/it]\r\n93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [00:30\u003C00:02,  1.35s/it]\r\n 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [00:30\u003C00:02,  1.35s/it]\r\n 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 28/30 [00:30\u003C00:02,  1.35s/it]\r\n97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [00:31\u003C00:01,  1.41s/it]\r\n97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [00:31\u003C00:01,  1.41s/it]\r\n97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [00:31\u003C00:01,  1.41s/it]\r\n97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [00:31\u003C00:01,  1.41s/it]\r\n97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [00:31\u003C00:01,  1.41s/it]\r\n97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [00:31\u003C00:01,  1.41s/it]\r\n97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [00:31\u003C00:01,  1.41s/it]\r\n 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 29/30 [00:31\u003C00:01,  1.41s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.45s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.45s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.45s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.45s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.45s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.45s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.45s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.11s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.11s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.11s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.11s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.11s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.11s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.11s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.45s/it]\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [00:33\u003C00:00,  1.11s/it]\r\nTime elapsed: 37.30s\r\nSaving generated video to output.mp4", "metrics": {"predict_time": 39.239689968, "total_time": 38.569}, "output": "https://replicate.delivery/xezq/B08EdKGBIAK8E9rbNTX9jWO9ScVNbFivMaeXZM9ZUb5HAaKKA/output.mp4", "started_at": "2025-03-03T11:09:28Z", "status": "succeeded", "urls": {"stream": "https://stream.replicate.com/v1/files/bcwr-femi5qmvtz53zvgvrb5aabiayj55skrllvjb2jhbtjt3gmnxsmzq", "get": "https://api.replicate.com/v1/predictions/5kgmyvakxxrme0cnbesb198s0r", "cancel": "https://api.replicate.com/v1/predictions/5kgmyvakxxrme0cnbesb198s0r/cancel"}, "_extras": {"api_token_name": null, "created_by": {"kind": "organization", "url": "https://replicate.com/wavespeedai", "username": "wavespeedai"}, "input_files": ["https://replicate.delivery/pbxt/MZZyui7brAbh1d2AsyPtgPIByUwzSv6Uou8objC7zXEjLySc/1a8nt7yw5drm80cn05r89mjce0.png"], "is_immutable": false, "is_shared": true, "is_waiting_for_boot": null, "may_have_sensitive_output": false, "output_files": ["https://replicate.delivery/xezq/B08EdKGBIAK8E9rbNTX9jWO9ScVNbFivMaeXZM9ZUb5HAaKKA/output.mp4"], "pipeline_child_predictions": [], "ran_on": {"capabilities": {"hotswap": false, "run": true, "stream": false, "train": false}, "dereferenced_openapi_schema": {"info": {"title": "Cog", "version": "0.1.0"}, "paths": {"/": {"get": {"summary": "Root", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Root  Get"}}}, "description": "Successful Response"}}, "operationId": "root__get"}}, "/shutdown": {"post": {"summary": "Start Shutdown", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Start Shutdown Shutdown Post"}}}, "description": "Successful Response"}}, "operationId": "start_shutdown_shutdown_post"}}, "/predictions": {"post": {"summary": "Predict", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id"}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error"}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "description": "Random seed. Leave blank for random"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 1, "description": "Input image to start generating from"}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Prompt for video generation"}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "Maximum area of generated image. The input image will shrink to fit these dimensions", "default": "832x480", "x-order": 3}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Off", "x-order": 5}, "num_frames": {"type": "integer", "title": "Num Frames", "default": 81, "maximum": 100, "minimum": 81, "x-order": 2, "description": "Number of video frames. 81 frames give the best results"}, "sample_shift": {"type": "number", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 1, "x-order": 8, "description": "Sample shift factor"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "x-order": 6, "description": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts"}, "frames_per_second": {"type": "integer", "title": "Frames Per Second", "default": 16, "maximum": 24, "minimum": 5, "x-order": 4, "description": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 0, "x-order": 7, "description": "Higher guide scale makes prompt adherence better, but can reduce variation"}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics"}, "version": {"type": "string", "title": "Version"}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "started_at": {"type": "string", "title": "Started At", "format": "date-time"}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time"}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model", "operationId": "predict_predictions_post", "requestBody": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id"}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "description": "Random seed. Leave blank for random"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 1, "description": "Input image to start generating from"}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Prompt for video generation"}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "Maximum area of generated image. The input image will shrink to fit these dimensions", "default": "832x480", "x-order": 3}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Off", "x-order": 5}, "num_frames": {"type": "integer", "title": "Num Frames", "default": 81, "maximum": 100, "minimum": 81, "x-order": 2, "description": "Number of video frames. 81 frames give the best results"}, "sample_shift": {"type": "number", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 1, "x-order": 8, "description": "Sample shift factor"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "x-order": 6, "description": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts"}, "frames_per_second": {"type": "integer", "title": "Frames Per Second", "default": 16, "maximum": 24, "minimum": 5, "x-order": 4, "description": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 0, "x-order": 7, "description": "Higher guide scale makes prompt adherence better, but can reduce variation"}}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "output_file_prefix": {"type": "string", "title": "Output File Prefix"}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"]}}}}}}}}, "/health-check": {"get": {"summary": "Healthcheck", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Healthcheck Health Check Get"}}}, "description": "Successful Response"}}, "operationId": "healthcheck_health_check_get"}}, "/predictions/{prediction_id}": {"put": {"summary": "Predict Idempotent", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id"}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error"}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "description": "Random seed. Leave blank for random"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 1, "description": "Input image to start generating from"}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Prompt for video generation"}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "Maximum area of generated image. The input image will shrink to fit these dimensions", "default": "832x480", "x-order": 3}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Off", "x-order": 5}, "num_frames": {"type": "integer", "title": "Num Frames", "default": 81, "maximum": 100, "minimum": 81, "x-order": 2, "description": "Number of video frames. 81 frames give the best results"}, "sample_shift": {"type": "number", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 1, "x-order": 8, "description": "Sample shift factor"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "x-order": 6, "description": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts"}, "frames_per_second": {"type": "integer", "title": "Frames Per Second", "default": 16, "maximum": 24, "minimum": 5, "x-order": 4, "description": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 0, "x-order": 7, "description": "Higher guide scale makes prompt adherence better, but can reduce variation"}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics"}, "version": {"type": "string", "title": "Version"}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "started_at": {"type": "string", "title": "Started At", "format": "date-time"}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time"}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}, {"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model (idempotent creation).", "operationId": "predict_idempotent_predictions__prediction_id__put", "requestBody": {"content": {"application/json": {"schema": {"allOf": [{"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id"}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "description": "Random seed. Leave blank for random"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 1, "description": "Input image to start generating from"}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Prompt for video generation"}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "Maximum area of generated image. The input image will shrink to fit these dimensions", "default": "832x480", "x-order": 3}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Off", "x-order": 5}, "num_frames": {"type": "integer", "title": "Num Frames", "default": 81, "maximum": 100, "minimum": 81, "x-order": 2, "description": "Number of video frames. 81 frames give the best results"}, "sample_shift": {"type": "number", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 1, "x-order": 8, "description": "Sample shift factor"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "x-order": 6, "description": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts"}, "frames_per_second": {"type": "integer", "title": "Frames Per Second", "default": 16, "maximum": 24, "minimum": 5, "x-order": 4, "description": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 0, "x-order": 7, "description": "Higher guide scale makes prompt adherence better, but can reduce variation"}}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "output_file_prefix": {"type": "string", "title": "Output File Prefix"}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"]}}}], "title": "Prediction Request"}}}, "required": true}}}, "/predictions/{prediction_id}/cancel": {"post": {"summary": "Cancel", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Cancel Predictions  Prediction Id  Cancel Post"}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}], "description": "Cancel a running prediction", "operationId": "cancel_predictions__prediction_id__cancel_post"}}}, "openapi": "3.0.2", "components": {"schemas": {"Input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "description": "Random seed. Leave blank for random"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 1, "description": "Input image to start generating from"}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Prompt for video generation"}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "Maximum area of generated image. The input image will shrink to fit these dimensions", "default": "832x480", "x-order": 3}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Off", "x-order": 5}, "num_frames": {"type": "integer", "title": "Num Frames", "default": 81, "maximum": 100, "minimum": 81, "x-order": 2, "description": "Number of video frames. 81 frames give the best results"}, "sample_shift": {"type": "number", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 1, "x-order": 8, "description": "Sample shift factor"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "x-order": 6, "description": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts"}, "frames_per_second": {"type": "integer", "title": "Frames Per Second", "default": 16, "maximum": 24, "minimum": 5, "x-order": 4, "description": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 0, "x-order": 7, "description": "Higher guide scale makes prompt adherence better, but can reduce variation"}}}, "Output": {"type": "string", "title": "Output", "format": "uri"}, "Status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "An enumeration."}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "An enumeration."}, "WebhookEvent": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "ValidationError": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "PredictionRequest": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id"}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "description": "Random seed. Leave blank for random"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 1, "description": "Input image to start generating from"}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Prompt for video generation"}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "Maximum area of generated image. The input image will shrink to fit these dimensions", "default": "832x480", "x-order": 3}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Off", "x-order": 5}, "num_frames": {"type": "integer", "title": "Num Frames", "default": 81, "maximum": 100, "minimum": 81, "x-order": 2, "description": "Number of video frames. 81 frames give the best results"}, "sample_shift": {"type": "number", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 1, "x-order": 8, "description": "Sample shift factor"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "x-order": 6, "description": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts"}, "frames_per_second": {"type": "integer", "title": "Frames Per Second", "default": 16, "maximum": 24, "minimum": 5, "x-order": 4, "description": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 0, "x-order": 7, "description": "Higher guide scale makes prompt adherence better, but can reduce variation"}}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "output_file_prefix": {"type": "string", "title": "Output File Prefix"}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"]}}}, "PredictionResponse": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id"}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error"}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "description": "Random seed. Leave blank for random"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 1, "description": "Input image to start generating from"}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Prompt for video generation"}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "Maximum area of generated image. The input image will shrink to fit these dimensions", "default": "832x480", "x-order": 3}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Off", "x-order": 5}, "num_frames": {"type": "integer", "title": "Num Frames", "default": 81, "maximum": 100, "minimum": 81, "x-order": 2, "description": "Number of video frames. 81 frames give the best results"}, "sample_shift": {"type": "number", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 1, "x-order": 8, "description": "Sample shift factor"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "x-order": 6, "description": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts"}, "frames_per_second": {"type": "integer", "title": "Frames Per Second", "default": 16, "maximum": 24, "minimum": 5, "x-order": 4, "description": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 0, "x-order": 7, "description": "Higher guide scale makes prompt adherence better, but can reduce variation"}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics"}, "version": {"type": "string", "title": "Version"}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "started_at": {"type": "string", "title": "Started At", "format": "date-time"}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time"}}}, "HTTPValidationError": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}}, "hardware": {"arch": "gpu", "display_name": "8x Nvidia H100 GPU", "short_display_name": "8x H100", "sku": "gpu-h100-8x"}, "has_special_pricing": true, "is_official": true, "kind": "model", "model": {"name": "wan-2.1-i2v-480p", "username": "wavespeedai", "visibility": "public"}, "supports_cancelation": false, "url": "https://replicate.com/wavespeedai/wan-2.1-i2v-480p"}, "source": "web", "total_child_predictions": 0}, "version": "hidden"}, "initialPredictionVersion": {"id": "ebc62a092ff0d934d3b3677e5a555d8ffbc810411ad276d2524f6df3aea9b8ec", "created_at": "2025-03-02T14:20:57.922600Z", "_extras": {"arch": "gpu", "dereferenced_openapi_schema": {"info": {"title": "Cog", "version": "0.1.0"}, "paths": {"/": {"get": {"summary": "Root", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Root  Get"}}}, "description": "Successful Response"}}, "operationId": "root__get"}}, "/shutdown": {"post": {"summary": "Start Shutdown", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Start Shutdown Shutdown Post"}}}, "description": "Successful Response"}}, "operationId": "start_shutdown_shutdown_post"}}, "/predictions": {"post": {"summary": "Predict", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id"}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error"}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "description": "Random seed. Leave blank for random"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 1, "description": "Input image to start generating from"}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Prompt for video generation"}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "Maximum area of generated image. The input image will shrink to fit these dimensions", "default": "832x480", "x-order": 3}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Off", "x-order": 5}, "num_frames": {"type": "integer", "title": "Num Frames", "default": 81, "maximum": 100, "minimum": 81, "x-order": 2, "description": "Number of video frames. 81 frames give the best results"}, "sample_shift": {"type": "number", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 1, "x-order": 8, "description": "Sample shift factor"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "x-order": 6, "description": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts"}, "frames_per_second": {"type": "integer", "title": "Frames Per Second", "default": 16, "maximum": 24, "minimum": 5, "x-order": 4, "description": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 0, "x-order": 7, "description": "Higher guide scale makes prompt adherence better, but can reduce variation"}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics"}, "version": {"type": "string", "title": "Version"}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "started_at": {"type": "string", "title": "Started At", "format": "date-time"}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time"}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model", "operationId": "predict_predictions_post", "requestBody": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id"}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "description": "Random seed. Leave blank for random"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 1, "description": "Input image to start generating from"}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Prompt for video generation"}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "Maximum area of generated image. The input image will shrink to fit these dimensions", "default": "832x480", "x-order": 3}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Off", "x-order": 5}, "num_frames": {"type": "integer", "title": "Num Frames", "default": 81, "maximum": 100, "minimum": 81, "x-order": 2, "description": "Number of video frames. 81 frames give the best results"}, "sample_shift": {"type": "number", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 1, "x-order": 8, "description": "Sample shift factor"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "x-order": 6, "description": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts"}, "frames_per_second": {"type": "integer", "title": "Frames Per Second", "default": 16, "maximum": 24, "minimum": 5, "x-order": 4, "description": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 0, "x-order": 7, "description": "Higher guide scale makes prompt adherence better, but can reduce variation"}}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "output_file_prefix": {"type": "string", "title": "Output File Prefix"}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"]}}}}}}}}, "/health-check": {"get": {"summary": "Healthcheck", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Healthcheck Health Check Get"}}}, "description": "Successful Response"}}, "operationId": "healthcheck_health_check_get"}}, "/predictions/{prediction_id}": {"put": {"summary": "Predict Idempotent", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id"}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error"}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "description": "Random seed. Leave blank for random"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 1, "description": "Input image to start generating from"}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Prompt for video generation"}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "Maximum area of generated image. The input image will shrink to fit these dimensions", "default": "832x480", "x-order": 3}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Off", "x-order": 5}, "num_frames": {"type": "integer", "title": "Num Frames", "default": 81, "maximum": 100, "minimum": 81, "x-order": 2, "description": "Number of video frames. 81 frames give the best results"}, "sample_shift": {"type": "number", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 1, "x-order": 8, "description": "Sample shift factor"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "x-order": 6, "description": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts"}, "frames_per_second": {"type": "integer", "title": "Frames Per Second", "default": 16, "maximum": 24, "minimum": 5, "x-order": 4, "description": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 0, "x-order": 7, "description": "Higher guide scale makes prompt adherence better, but can reduce variation"}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics"}, "version": {"type": "string", "title": "Version"}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "started_at": {"type": "string", "title": "Started At", "format": "date-time"}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time"}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}, {"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model (idempotent creation).", "operationId": "predict_idempotent_predictions__prediction_id__put", "requestBody": {"content": {"application/json": {"schema": {"allOf": [{"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id"}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "description": "Random seed. Leave blank for random"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 1, "description": "Input image to start generating from"}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Prompt for video generation"}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "Maximum area of generated image. The input image will shrink to fit these dimensions", "default": "832x480", "x-order": 3}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Off", "x-order": 5}, "num_frames": {"type": "integer", "title": "Num Frames", "default": 81, "maximum": 100, "minimum": 81, "x-order": 2, "description": "Number of video frames. 81 frames give the best results"}, "sample_shift": {"type": "number", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 1, "x-order": 8, "description": "Sample shift factor"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "x-order": 6, "description": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts"}, "frames_per_second": {"type": "integer", "title": "Frames Per Second", "default": 16, "maximum": 24, "minimum": 5, "x-order": 4, "description": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 0, "x-order": 7, "description": "Higher guide scale makes prompt adherence better, but can reduce variation"}}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "output_file_prefix": {"type": "string", "title": "Output File Prefix"}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"]}}}], "title": "Prediction Request"}}}, "required": true}}}, "/predictions/{prediction_id}/cancel": {"post": {"summary": "Cancel", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Cancel Predictions  Prediction Id  Cancel Post"}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}], "description": "Cancel a running prediction", "operationId": "cancel_predictions__prediction_id__cancel_post"}}}, "openapi": "3.0.2", "components": {"schemas": {"Input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "description": "Random seed. Leave blank for random"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 1, "description": "Input image to start generating from"}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Prompt for video generation"}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "Maximum area of generated image. The input image will shrink to fit these dimensions", "default": "832x480", "x-order": 3}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Off", "x-order": 5}, "num_frames": {"type": "integer", "title": "Num Frames", "default": 81, "maximum": 100, "minimum": 81, "x-order": 2, "description": "Number of video frames. 81 frames give the best results"}, "sample_shift": {"type": "number", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 1, "x-order": 8, "description": "Sample shift factor"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "x-order": 6, "description": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts"}, "frames_per_second": {"type": "integer", "title": "Frames Per Second", "default": 16, "maximum": 24, "minimum": 5, "x-order": 4, "description": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 0, "x-order": 7, "description": "Higher guide scale makes prompt adherence better, but can reduce variation"}}}, "Output": {"type": "string", "title": "Output", "format": "uri"}, "Status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "An enumeration."}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "An enumeration."}, "WebhookEvent": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "ValidationError": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "PredictionRequest": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id"}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "description": "Random seed. Leave blank for random"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 1, "description": "Input image to start generating from"}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Prompt for video generation"}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "Maximum area of generated image. The input image will shrink to fit these dimensions", "default": "832x480", "x-order": 3}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Off", "x-order": 5}, "num_frames": {"type": "integer", "title": "Num Frames", "default": 81, "maximum": 100, "minimum": 81, "x-order": 2, "description": "Number of video frames. 81 frames give the best results"}, "sample_shift": {"type": "number", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 1, "x-order": 8, "description": "Sample shift factor"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "x-order": 6, "description": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts"}, "frames_per_second": {"type": "integer", "title": "Frames Per Second", "default": 16, "maximum": 24, "minimum": 5, "x-order": 4, "description": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 0, "x-order": 7, "description": "Higher guide scale makes prompt adherence better, but can reduce variation"}}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "output_file_prefix": {"type": "string", "title": "Output File Prefix"}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"]}}}, "PredictionResponse": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id"}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error"}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "description": "Random seed. Leave blank for random"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 1, "description": "Input image to start generating from"}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Prompt for video generation"}, "max_area": {"enum": ["832x480", "480x832"], "type": "string", "title": "max_area", "description": "Maximum area of generated image. The input image will shrink to fit these dimensions", "default": "832x480", "x-order": 3}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Off", "x-order": 5}, "num_frames": {"type": "integer", "title": "Num Frames", "default": 81, "maximum": 100, "minimum": 81, "x-order": 2, "description": "Number of video frames. 81 frames give the best results"}, "sample_shift": {"type": "number", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 1, "x-order": 8, "description": "Sample shift factor"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "x-order": 6, "description": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts"}, "frames_per_second": {"type": "integer", "title": "Frames Per Second", "default": 16, "maximum": 24, "minimum": 5, "x-order": 4, "description": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 0, "x-order": 7, "description": "Higher guide scale makes prompt adherence better, but can reduce variation"}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics"}, "version": {"type": "string", "title": "Version"}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "started_at": {"type": "string", "title": "Started At", "format": "date-time"}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time"}}}, "HTTPValidationError": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}}, "disabled_for_predictions": false, "disabled_for_trainings": false, "model": {"cover_image_url": "https://replicate.delivery/xezq/ZyWZxK0QxY4YPlIKx4MtoaRspem81q7rMaacQEj3vqyyuqJKA/output.mp4", "description": null, "hardware": null, "latest_version": {"id": "c166c026d33405455f2c8da230f5e4bf09efac09a539af0f494a13ed5aa6929d"}, "name": "wavespeed-wan-2.1-i2v-480p-internal-model", "owner": "replicate", "url": "https://replicate.com/replicate/wavespeed-wan-2.1-i2v-480p-internal-model", "visibility": "private", "_extras": {"name": "replicate/wavespeed-wan-2.1-i2v-480p-internal-model", "is_official": false, "is_pipeline": false}}, "name": "replicate/wavespeed-wan-2.1-i2v-480p-internal-model:ebc62a09", "release_notes": null, "short_id": "ebc62a09", "url": "https://replicate.com/replicate/wavespeed-wan-2.1-i2v-480p-internal-model/versions/ebc62a092ff0d934d3b3677e5a555d8ffbc810411ad276d2524f6df3aea9b8ec"}}, "isAuthenticated": false, "features": {"show_pipeline_steps": false, "show_before_after_slider_output": false, "show_goo_shader_output": false, "link_to_video_upscaler": true, "link_to_image_upscaler": false, "link_to_playground": true, "link_to_audio_adder": false, "pixelate_images": false}, "permissions": {"create_example": false, "debug": false, "edit_featured_inputs": false, "report": true, "run": false, "tweak": true, "delete": false, "share": true}, "model": {"cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/75f0346d-ec4c-4078-bb40-6705578c0d21/replicate-prediction-br080xq9.webp", "description": "Accelerated inference for Wan 2.1 14B image to video, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation.", "hardware": "CPU", "latest_version": {"id": "70cc41f08f08a92133c0446992f846d86959f9eb7d7733d6a7a15b08062ef3cc"}, "name": "wan-2.1-i2v-480p", "owner": "wavespeedai", "url": "https://replicate.com/wavespeedai/wan-2.1-i2v-480p", "visibility": "public", "_extras": {"name": "wavespeedai/wan-2.1-i2v-480p", "is_official": true, "is_pipeline": false}}, "schema": {"info": {"title": "Cog", "version": "0.1.0"}, "paths": {"/": {"get": {"summary": "Root", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Root  Get"}}}, "description": "Successful Response"}}, "operationId": "root__get"}}, "/shutdown": {"post": {"summary": "Start Shutdown", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Start Shutdown Shutdown Post"}}}, "description": "Successful Response"}}, "operationId": "start_shutdown_shutdown_post"}}, "/predictions": {"post": {"summary": "Predict", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "nullable": true, "description": "Random seed. Set for reproducible generation"}, "image": {"type": "string", "title": "Image", "format": "uri", "description": "Image for use as the initial frame of the video."}, "prompt": {"type": "string", "title": "Prompt", "description": "Text prompt for image generation"}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Balanced", "x-order": 4}, "lora_scale": {"type": "number", "title": "Lora Scale", "default": 1, "maximum": 4, "minimum": 0, "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. You may still need to experiment to find the best value for your particular lora."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Aspect ratio of the output video.", "default": "16:9", "x-order": 2}, "lora_weights": {"type": "string", "title": "Lora Weights", "nullable": true, "description": "Load LoRA weights. Supports HuggingFace URLs in the format huggingface.co/\u003Cowner\u003E/\u003Cmodel-name\u003E, CivitAI URLs in the format civitai.com/models/\u003Cid\u003E[/\u003Cmodel-name\u003E], or arbitrary .safetensors URLs from the Internet."}, "sample_shift": {"type": "integer", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 0, "description": "Flow shift parameter for video generation"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "description": "Number of inference steps"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "default": "", "description": "Negative prompt to avoid certain elements"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 1, "description": "Guidance scale for generation"}, "disable_safety_checker": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "description": "Disable safety checker for generated videos"}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model", "operationId": "predict_predictions_post", "requestBody": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "nullable": true, "description": "Random seed. Set for reproducible generation"}, "image": {"type": "string", "title": "Image", "format": "uri", "description": "Image for use as the initial frame of the video."}, "prompt": {"type": "string", "title": "Prompt", "description": "Text prompt for image generation"}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Balanced", "x-order": 4}, "lora_scale": {"type": "number", "title": "Lora Scale", "default": 1, "maximum": 4, "minimum": 0, "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. You may still need to experiment to find the best value for your particular lora."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Aspect ratio of the output video.", "default": "16:9", "x-order": 2}, "lora_weights": {"type": "string", "title": "Lora Weights", "nullable": true, "description": "Load LoRA weights. Supports HuggingFace URLs in the format huggingface.co/\u003Cowner\u003E/\u003Cmodel-name\u003E, CivitAI URLs in the format civitai.com/models/\u003Cid\u003E[/\u003Cmodel-name\u003E], or arbitrary .safetensors URLs from the Internet."}, "sample_shift": {"type": "integer", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 0, "description": "Flow shift parameter for video generation"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "description": "Number of inference steps"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "default": "", "description": "Negative prompt to avoid certain elements"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 1, "description": "Guidance scale for generation"}, "disable_safety_checker": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "description": "Disable safety checker for generated videos"}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}}}}}}, "/health-check": {"get": {"summary": "Healthcheck", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Healthcheck Health Check Get"}}}, "description": "Successful Response"}}, "operationId": "healthcheck_health_check_get"}}, "/predictions/{prediction_id}": {"put": {"summary": "Predict Idempotent", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "nullable": true, "description": "Random seed. Set for reproducible generation"}, "image": {"type": "string", "title": "Image", "format": "uri", "description": "Image for use as the initial frame of the video."}, "prompt": {"type": "string", "title": "Prompt", "description": "Text prompt for image generation"}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Balanced", "x-order": 4}, "lora_scale": {"type": "number", "title": "Lora Scale", "default": 1, "maximum": 4, "minimum": 0, "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. You may still need to experiment to find the best value for your particular lora."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Aspect ratio of the output video.", "default": "16:9", "x-order": 2}, "lora_weights": {"type": "string", "title": "Lora Weights", "nullable": true, "description": "Load LoRA weights. Supports HuggingFace URLs in the format huggingface.co/\u003Cowner\u003E/\u003Cmodel-name\u003E, CivitAI URLs in the format civitai.com/models/\u003Cid\u003E[/\u003Cmodel-name\u003E], or arbitrary .safetensors URLs from the Internet."}, "sample_shift": {"type": "integer", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 0, "description": "Flow shift parameter for video generation"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "description": "Number of inference steps"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "default": "", "description": "Negative prompt to avoid certain elements"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 1, "description": "Guidance scale for generation"}, "disable_safety_checker": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "description": "Disable safety checker for generated videos"}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}, {"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model (idempotent creation).", "operationId": "predict_idempotent_predictions__prediction_id__put", "requestBody": {"content": {"application/json": {"schema": {"allOf": [{"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "nullable": true, "description": "Random seed. Set for reproducible generation"}, "image": {"type": "string", "title": "Image", "format": "uri", "description": "Image for use as the initial frame of the video."}, "prompt": {"type": "string", "title": "Prompt", "description": "Text prompt for image generation"}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Balanced", "x-order": 4}, "lora_scale": {"type": "number", "title": "Lora Scale", "default": 1, "maximum": 4, "minimum": 0, "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. You may still need to experiment to find the best value for your particular lora."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Aspect ratio of the output video.", "default": "16:9", "x-order": 2}, "lora_weights": {"type": "string", "title": "Lora Weights", "nullable": true, "description": "Load LoRA weights. Supports HuggingFace URLs in the format huggingface.co/\u003Cowner\u003E/\u003Cmodel-name\u003E, CivitAI URLs in the format civitai.com/models/\u003Cid\u003E[/\u003Cmodel-name\u003E], or arbitrary .safetensors URLs from the Internet."}, "sample_shift": {"type": "integer", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 0, "description": "Flow shift parameter for video generation"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "description": "Number of inference steps"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "default": "", "description": "Negative prompt to avoid certain elements"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 1, "description": "Guidance scale for generation"}, "disable_safety_checker": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "description": "Disable safety checker for generated videos"}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}], "title": "Prediction Request"}}}, "required": true}}}, "/predictions/{prediction_id}/cancel": {"post": {"summary": "Cancel", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Cancel Predictions  Prediction Id  Cancel Post"}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}], "description": "Cancel a running prediction", "operationId": "cancel_predictions__prediction_id__cancel_post"}}}, "openapi": "3.0.2", "components": {"schemas": {"Input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "nullable": true, "description": "Random seed. Set for reproducible generation"}, "image": {"type": "string", "title": "Image", "format": "uri", "description": "Image for use as the initial frame of the video."}, "prompt": {"type": "string", "title": "Prompt", "description": "Text prompt for image generation"}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Balanced", "x-order": 4}, "lora_scale": {"type": "number", "title": "Lora Scale", "default": 1, "maximum": 4, "minimum": 0, "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. You may still need to experiment to find the best value for your particular lora."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Aspect ratio of the output video.", "default": "16:9", "x-order": 2}, "lora_weights": {"type": "string", "title": "Lora Weights", "nullable": true, "description": "Load LoRA weights. Supports HuggingFace URLs in the format huggingface.co/\u003Cowner\u003E/\u003Cmodel-name\u003E, CivitAI URLs in the format civitai.com/models/\u003Cid\u003E[/\u003Cmodel-name\u003E], or arbitrary .safetensors URLs from the Internet."}, "sample_shift": {"type": "integer", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 0, "description": "Flow shift parameter for video generation"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "description": "Number of inference steps"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "default": "", "description": "Negative prompt to avoid certain elements"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 1, "description": "Guidance scale for generation"}, "disable_safety_checker": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "description": "Disable safety checker for generated videos"}}}, "Output": {"type": "string", "title": "Output", "format": "uri"}, "Status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "An enumeration."}, "WebhookEvent": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "An enumeration."}, "ValidationError": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "PredictionRequest": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "nullable": true, "description": "Random seed. Set for reproducible generation"}, "image": {"type": "string", "title": "Image", "format": "uri", "description": "Image for use as the initial frame of the video."}, "prompt": {"type": "string", "title": "Prompt", "description": "Text prompt for image generation"}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Balanced", "x-order": 4}, "lora_scale": {"type": "number", "title": "Lora Scale", "default": 1, "maximum": 4, "minimum": 0, "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. You may still need to experiment to find the best value for your particular lora."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Aspect ratio of the output video.", "default": "16:9", "x-order": 2}, "lora_weights": {"type": "string", "title": "Lora Weights", "nullable": true, "description": "Load LoRA weights. Supports HuggingFace URLs in the format huggingface.co/\u003Cowner\u003E/\u003Cmodel-name\u003E, CivitAI URLs in the format civitai.com/models/\u003Cid\u003E[/\u003Cmodel-name\u003E], or arbitrary .safetensors URLs from the Internet."}, "sample_shift": {"type": "integer", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 0, "description": "Flow shift parameter for video generation"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "description": "Number of inference steps"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "default": "", "description": "Negative prompt to avoid certain elements"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 1, "description": "Guidance scale for generation"}, "disable_safety_checker": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "description": "Disable safety checker for generated videos"}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}, "PredictionResponse": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt", "image"], "properties": {"seed": {"type": "integer", "title": "Seed", "nullable": true, "description": "Random seed. Set for reproducible generation"}, "image": {"type": "string", "title": "Image", "format": "uri", "description": "Image for use as the initial frame of the video."}, "prompt": {"type": "string", "title": "Prompt", "description": "Text prompt for image generation"}, "fast_mode": {"enum": ["Off", "Balanced", "Fast"], "type": "string", "title": "fast_mode", "description": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.", "default": "Balanced", "x-order": 4}, "lora_scale": {"type": "number", "title": "Lora Scale", "default": 1, "maximum": 4, "minimum": 0, "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. You may still need to experiment to find the best value for your particular lora."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Aspect ratio of the output video.", "default": "16:9", "x-order": 2}, "lora_weights": {"type": "string", "title": "Lora Weights", "nullable": true, "description": "Load LoRA weights. Supports HuggingFace URLs in the format huggingface.co/\u003Cowner\u003E/\u003Cmodel-name\u003E, CivitAI URLs in the format civitai.com/models/\u003Cid\u003E[/\u003Cmodel-name\u003E], or arbitrary .safetensors URLs from the Internet."}, "sample_shift": {"type": "integer", "title": "Sample Shift", "default": 3, "maximum": 10, "minimum": 0, "description": "Flow shift parameter for video generation"}, "sample_steps": {"type": "integer", "title": "Sample Steps", "default": 30, "maximum": 40, "minimum": 1, "description": "Number of inference steps"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "default": "", "description": "Negative prompt to avoid certain elements"}, "sample_guide_scale": {"type": "number", "title": "Sample Guide Scale", "default": 5, "maximum": 10, "minimum": 1, "description": "Guidance scale for generation"}, "disable_safety_checker": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "description": "Disable safety checker for generated videos"}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}, "HTTPValidationError": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}}, "token": "", "modelStatus": "online", "modelInputSettings": {"hidden": []}, "requiresCredit": true, "__flags": {"show-open-ai-api-instructions": false, "show-pylon-widget": false, "assign-support-tickets-to-ai": false}}</script>

  <div data-react-placeholder="APIPlayground">
    <div class="input-output-grid">
  <div class="flex flex-col md:flex-row">
    <div class="input-col relative md:flex-1 pb-4 min-w-0">
      <div class="mb-2 flex items-center justify-between">
        <div class="flex-1">
          <div class="mb-4 bg-r8-gray-4 animate-pulse h-8 w-24">
          </div>
        </div>
      </div>
      <div class="h-8 bg-r8-gray-4 animate-pulse mb-6">
      </div>
      <div class="space-y-4">
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
      </div>
    </div>
    <div class="input-output-grid--divider flex-shrink-0 md:mx-6 mb-6 md:my-0"
         role="separator">
      <div class="bg-r8-gray-6 md:w-px md:h-full h-px w-full">
      </div>
    </div>
    <div class="output-col md:flex-1 pb-4 min-w-0">
      <div class="flex flex-col">
        <div class="flex-1">
          <div class="mb-4 bg-r8-gray-4 animate-pulse h-8 w-24">
          </div>
        </div>
        <div class="h-8 bg-r8-gray-4 animate-pulse mb-6">
        </div>
        <div class="aspect-square bg-r8-gray-4 animate-pulse">
        </div>
      </div>
    </div>
  </div>
</div>

  </div>

<div data-component="APIPlayground"
     data-props="react-component-props-ec08bc0f-f57c-402f-8684-3e6b70ca5b1f">
  
</div>

  
</div>

    



  
  
  
    <div class="pb-2 border-b border-r8-gray-5 mb-lh flex">
      <h2 class="inline-block flex-grow text-r8-2xl">
        Examples
      </h2>

      <p>
        <a href="/wavespeedai/wan-2.1-i2v-480p/examples"
           class="no-default">
          View more <span class="hidden sm:inline">examples</span><span class="relative -top-0.5">
          
<svg xmlns="http://www.w3.org/2000/svg"
     width="24"
     height="24"
     viewBox="0 0 24 24"
     fill="none"
     stroke="currentColor"
     stroke-width="1.5"
     stroke-linecap="round"
     stroke-linejoin="round"
     class="icon">
  <line x1="7" y1="17" x2="17" y2="7"></line>
  <polyline points="7 7 17 7 17 17"></polyline>
</svg>

        </span></a>
      </p>
    </div>

    <div class="mb-2lh h-40 overflow-hidden ">
      
        
          <div class="inline-block h-40 w-40 overflow-hidden">
            <a class="relative"
               href="/wavespeedai/wan-2.1-i2v-480p/examples#xbgccvx6h1rmc0cn90n8pzrefw">

              
                <video data-src="https://replicate.delivery/xezq/UyajaOSJCu4GD9lCtmytldnSWx0ynkPfedtaTyfRLnijBInoA/output.mp4"
                       type="video/mp4"
                       autoplay
                       muted
                       loop
                       role="presentation"
                       class="object-cover object-center w-full h-full lazy" />
              

            </a>
          </div>
        
      
        
          <div class="inline-block h-40 w-40 overflow-hidden">
            <a class="relative"
               href="/wavespeedai/wan-2.1-i2v-480p/examples#5kgmyvakxxrme0cnbesb198s0r">

              
                <video data-src="https://replicate.delivery/xezq/B08EdKGBIAK8E9rbNTX9jWO9ScVNbFivMaeXZM9ZUb5HAaKKA/output.mp4"
                       type="video/mp4"
                       autoplay
                       muted
                       loop
                       role="presentation"
                       class="object-cover object-center w-full h-full lazy" />
              

            </a>
          </div>
        
      
        
          <div class="inline-block h-40 w-40 overflow-hidden">
            <a class="relative"
               href="/wavespeedai/wan-2.1-i2v-480p/examples#51sayrewbdrm80cnsq7avvcexr">

              
                <video data-src="https://replicate.delivery/xezq/aWTfAuK8om0WMCZLoDSJ2n0neiGaUjmPlfqxtmh9nvvhzO4oA/output.mp4"
                       type="video/mp4"
                       autoplay
                       muted
                       loop
                       role="presentation"
                       class="object-cover object-center w-full h-full lazy" />
              

            </a>
          </div>
        
      
    </div>
  




    
      

<section id="pricing"
         class="mb-2lh">

  <script id="react-component-props-18554357-e6d6-4ef6-bf58-10d7e7f517c3" type="application/json">{"billingConfig": {"current_description": null, "current_tiers": [{"criteria": [], "description": null, "prices": [{"description": "or around 11 seconds for $1", "metric": "video_output_duration_seconds", "metric_display": "second of output video", "price": "$0.09", "title": "per second of output video", "type": "per-unit"}], "title": null}]}, "modelName": "wavespeedai/wan-2.1-i2v-480p", "showTable": false, "__flags": {"show-open-ai-api-instructions": false, "show-pylon-widget": false, "assign-support-tickets-to-ai": false}}</script>

<div data-component="ModelBilling"
     data-props="react-component-props-18554357-e6d6-4ef6-bf58-10d7e7f517c3">
  
</div>

</section>

    

    

<article class="mb-2lh">
  
    <div id="readme"
         class="border-b border-r8-gray-5 pb-2 mb-lh flex items-center gap-2">
      <h2 class="inline-block text-r8-2xl">
        Readme
      </h2>
      
    </div>
  
  
    <div class="readme-prose max-w-4xl">
      <h1 id="accelerated-inference-for-wan-21-14b-image-to-video">Accelerated Inference for Wan 2.1 14B Image-to-Video</h1>
<p>We are <a href="https://wavespeed.ai/" rel="nofollow ugc"><code>WaveSpeedAI</code></a>, providing highly-optimized inference optimization for generative AI models.</p>
<p>We are excited to introduce our new product, a highly-optimized inference endpoint for <a href="https://github.com/Wan-Video/Wan2.1" rel="nofollow ugc"><code>Wan-2.1 14B</code></a> model, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation.</p>
<p>We utilize cutting-edge inference acceleration techniques to provide very fast inference for this model.
And we are happy to bring this to you together with <a href="http://replicate.com/" rel="nofollow ugc"><code>Replicate</code></a> and <a href="https://datacrunch.io/" rel="nofollow ugc"><code>DataCrunch</code></a>.</p>
<h2 id="model-description">Model Description </h2>
<p><a href="" rel="nofollow ugc" title=""><strong>Wan: Open and Advanced Large-Scale Video Generative Models</strong></a></p>
<p>In this repository, we present <strong>Wan2.1</strong>, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation. <strong>Wan2.1</strong> offers these key features:
-  <strong>SOTA Performance</strong>: <strong>Wan2.1</strong> consistently outperforms existing open-source models and state-of-the-art commercial solutions across multiple benchmarks.
-  <strong>Supports Consumer-grade GPUs</strong>: The T2V-1.3B model requires only 8.19 GB VRAM, making it compatible with almost all consumer-grade GPUs. It can generate a 5-second 480P video on an RTX 4090 in about 4 minutes (without optimization techniques like quantization). Its performance is even comparable to some closed-source models.
-  <strong>Multiple Tasks</strong>: <strong>Wan2.1</strong> excels in Text-to-Video, Image-to-Video, Video Editing, Text-to-Image, and Video-to-Audio, advancing the field of video generation.
-  <strong>Visual Text Generation</strong>: <strong>Wan2.1</strong> is the first video model capable of generating both Chinese and English text, featuring robust text generation that enhances its practical applications.
-  <strong>Powerful Video VAE</strong>: <strong>Wan-VAE</strong> delivers exceptional efficiency and performance, encoding and decoding 1080P videos of any length while preserving temporal information, making it an ideal foundation for video and image generation.</p>
    </div>
  
</article>

    




    <script id="react-component-props-88b22279-e7fc-4d15-b69c-bd43fecbc80f" type="application/json">{"name": "wavespeedai/wan-2.1-i2v-480p", "__flags": {"show-open-ai-api-instructions": false, "show-pylon-widget": false, "assign-support-tickets-to-ai": false}}</script>

<div data-component="RelatedModels"
     data-props="react-component-props-88b22279-e7fc-4d15-b69c-bd43fecbc80f">
  
</div>

  </div>


    </div>
  

  <div class="model-content mt-2lh">
    



  </div>



          
        
      </main>

      
        

<div class="footer no-focus">
  <script id="react-component-props-5a2a8c81-8a2b-46a3-8106-a16b4180c256" type="application/json">{"theme": "", "__flags": {"show-open-ai-api-instructions": false, "show-pylon-widget": false, "assign-support-tickets-to-ai": false}}</script>

<div data-component="Footer"
     data-props="react-component-props-5a2a8c81-8a2b-46a3-8106-a16b4180c256">
  
</div>

</div>

      

    

    <script nonce="xDxDFPBbzG01/nqc+Xuh7A==">
      window.VIDEOJS_NO_DYNAMIC_STYLE = true;
    </script>

    <script nonce="xDxDFPBbzG01/nqc+Xuh7A==">
      const header = document.getElementById("app-header");

      function monitorHeaderStickiness() {
        if (header) {
          header.setAttribute("data-stuck", window.scrollY > 0);
        }
      }

      monitorHeaderStickiness();

      document.addEventListener("scroll", (event) => {
        monitorHeaderStickiness();
      });

      // Prevent mousewheel from being able to change the value of a numeric input.
      // This "feature" often causes issues when users scroll from a focused input field
      // to the submit button and accidentally increment the contents of the field.
      document.addEventListener("wheel", (event) => {
        if (document.activeElement && document.activeElement.matches('input[type=number]') && document.activeElement === event.target) {
          event.preventDefault();
        }
      }, {
        passive: false
      });
    </script>

    
    
    

  </body>

</html>
