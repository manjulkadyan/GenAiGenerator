

<!DOCTYPE html>
<html lang="en"
      class="">

  <head>
    <meta charset="utf-8" />
    <title>
      
  
    google/veo-3.1 | Run with an API on Replicate
  

    </title>

    
      
      <meta name="viewport"
            content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    

    <link id="favicon-ico"
          rel="icon"
          href="https://d31rfu1d3w8e4q.cloudfront.net/static/favicon.121ea3afd763.ico"
          sizes="any" />
    <link id="favicon-png"
          rel="icon"
          href="https://d31rfu1d3w8e4q.cloudfront.net/static/favicon.fdf5ef8729cc.png"
          type="image/png" />
    <link rel="mask-icon"
          href="https://d31rfu1d3w8e4q.cloudfront.net/static/safari-pinned-tab.4c32b8e091a9.svg"
          color="#FFFFFF" />
    <link rel="apple-touch-icon"
          sizes="180x180"
          href="https://d31rfu1d3w8e4q.cloudfront.net/static/apple-touch-icon.39c0aa0659e3.png" />

    
  <script nonce="PpHLkEzMSKoBkzLZ38Dg0Q==">
    /* beautify ignore:start */
    window.dataLayer = window.dataLayer || [];
    
    
    dataLayer.push({
      'event': 'user_anonymous',
      'user_type': 'anonymous',
      
      'anonymous_session_id': 'cf34074d-0ebb-434a-8ad2-10ee90f8f83c'
      
    });
    
    /* beautify ignore:end */
  </script>
  <script nonce="PpHLkEzMSKoBkzLZ38Dg0Q==">
    (function(w, d, s, l, i) {
      w[l] = w[l] || [];
      w[l].push({
        'gtm.start': new Date().getTime(),
        event: 'gtm.js'
      });
      var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s),
        dl = l != 'dataLayer' ? '&l=' + l : '';
      j.async = true;
      j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
      f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-KZDCFZR9');
  </script>



    
    

    <link  rel="stylesheet" href="https://d31rfu1d3w8e4q.cloudfront.net/static/dist/index-BxwK8EBg.css" />
<script type="module" crossorigin="" src="https://d31rfu1d3w8e4q.cloudfront.net/static/dist/index-BK0wCkVE.js"></script>

    <link rel="stylesheet"
          href="https://d31rfu1d3w8e4q.cloudfront.net/static/dist/indexCss-D5iwNvwU.css" />

    <link rel="alternate"
          type="application/rss+xml"
          title="Blog (RSS)"
          href="https://replicate.com/blog/rss" />
    <link rel="alternate"
          type="application/atom+xml"
          title="Blog (Atom)"
          href="https://replicate.com/blog/atom" />
    <link rel="alternate"
          type="application/rss+xml"
          title="Changelog (RSS)"
          href="https://replicate.com/changelog/rss" />
    <link rel="alternate"
          type="application/atom+xml"
          title="Changelog (Atom)"
          href="https://replicate.com/changelog/atom" />
    <link rel="alternate"
          type="application/rss+xml"
          title="Status (RSS)"
          href="https://replicatestatus.com/feed" />

    
      <link rel="dns-prefetch"
            href="https://replicate.delivery" />
    
      <link rel="dns-prefetch"
            href="https://tjzk.replicate.delivery" />
    

    

    <link rel="canonical"
          href="https://replicate.com/google/veo-3.1" />

    
  
  
    
  

  <meta name="twitter:card"
        content="summary_large_image" />


<meta name="twitter:site"
      content="@replicate" />


  <meta name="twitter:image"
        content="https://og-api.replicateassets.com/api/models/google/veo-3.1" />
  <meta property="og:image"
        content="https://og-api.replicateassets.com/api/models/google/veo-3.1" />




  <meta name="twitter:title"
        content="google/veo-3.1 â€“ Replicate" />
  <meta name="twitter:description"
        content="New and improved version of Veo 3, with higher-fidelity video, context-aware audio, reference image and last frame support" />
  <meta property="og:image"
        content="https://og-api.replicateassets.com/api/models/google/veo-3.1" />
  <meta property="twitter:image"
        content="https://og-api.replicateassets.com/api/models/google/veo-3.1" />

  

  
    <meta name="description"
          content="New and improved version of Veo 3, with higher-fidelity video, context-aware audio, reference image and last frame support" />
  


    <meta name="sentry-dsn-js"
          content="https://3dc017e574684610bbc7fd3b5519a4e8@o255771.ingest.sentry.io/5909364" />
    
    
      <meta name="anonymous-id"
            content="cf34074d-0ebb-434a-8ad2-10ee90f8f83c" />
    

    
      <script nonce="PpHLkEzMSKoBkzLZ38Dg0Q==">
        const prefersDarkScheme = window.matchMedia('(prefers-color-scheme: dark)').matches;

        if (prefersDarkScheme) {
          document.documentElement.classList.add("dark");
        } else {
          document.documentElement.classList.add("light");
        }
      </script>
    

    
  </head>

  

  <body class="font-sans overflow-y-scroll antialiased flex min-h-screen flex-col">
    
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KZDCFZR9"
        height="0"
        width="0"
        style="display:none;
               visibility:hidden"></iframe></noscript>


    

      

      
        

<div class="h-[var(--header-height)] mb-6 no-focus">
  
    <script id="react-component-props-4f70e757-5331-45a0-8a2a-85d806dad5c9" type="application/json">{"activePath": "/google/veo-3.1", "isAuthenticated": false, "theme": "", "__flags": {"show-pylon-widget": false, "assign-support-tickets-to-ai": false, "show-open-ai-api-instructions": false}}</script>

<div data-component="Navigation"
     data-props="react-component-props-4f70e757-5331-45a0-8a2a-85d806dad5c9">
  
</div>

  
</div>

        



      

      
      

      
      

      

      <main class="layout-main flex-1">
        

        
          

  
  
  
    
      

    
      
    

    

    
      

<header class="space-y-4 pb-10 lg:pb-4"
        aria-label="google/veo-3.1">

  

<div class="flex gap-8 gap-y-4 w-full flex-wrap justify-between items-center">
  <div class="space-y-4">
    <div class="flex-wrap flex flex-col gap-1">

      <div class="flex gap-2 sm:gap-3 w-full">

        <h3 aria-label="google/veo-3.1"
            class="sr-only">
          google/veo-3.1
        </h3>

        <div translate="no"
             aria-hidden="true"
             class="flex relative items-center gap-1 flex-1 flex-wrap">
          <div class="flex items-center gap-3 whitespace-nowrap">
            
              


  <img class="avatar size-9 flex-shrink-0"
       src="https://tjzk.replicate.delivery/models_organizations_avatar/27e1e3fe-f766-4748-83b3-777bc282d8dd/1342004.png"
       alt=""
       role="presentation"
       onerror="this.onerror=null; this.src='https://d31rfu1d3w8e4q.cloudfront.net/static/placeholder-avatar-organization.ff98795474e8.svg'" />


            
            <div class="text-r8-gray-11 text-lg font-heading">
              
                <a href="https://replicate.com/google">google</a>
              
            </div>
            <div class="text-r8-gray-11 text-lg font-heading">
              /
            </div>
          </div>
          <div>
            <span class="text-lg font-heading">
              veo-3.1
            </span>
            <span class="[&>div]:inline">
              
                <script id="react-component-props-e1a73caa-2838-4c14-8d91-e726a452c1cc" type="application/json">{"identifier": "google/veo-3.1", "__flags": {"show-pylon-widget": false, "assign-support-tickets-to-ai": false, "show-open-ai-api-instructions": false}}</script>

<div data-component="CopyIdentifierButton"
     data-props="react-component-props-e1a73caa-2838-4c14-8d91-e726a452c1cc">
  
</div>

              
            </span>
          </div>
        </div>
      </div>

      

    </div>
  </div>

  <div class="relative flex flex-wrap gap-2 md:justify-end w-full md:w-auto">

    

    

    <div>
      <script id="react-component-props-b65cbf38-4788-404d-a754-2ccf81b91123" type="application/json">{"model": {"cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/7600d853-2847-4c46-afc9-faef04fea2c5/veo3.1-sm.mp4", "description": "New and improved version of Veo 3, with higher-fidelity video, context-aware audio, reference image and last frame support", "hardware": "CPU", "latest_version": {"id": "20ebd92c5919f20e8fa2e983bdb60016a99794c9accfab496ea25a68e0dbbaad"}, "name": "veo-3.1", "owner": "google", "url": "https://replicate.com/google/veo-3.1", "visibility": "public", "_extras": {"name": "google/veo-3.1", "is_official": true, "is_pipeline": false}}, "__flags": {"show-pylon-widget": false, "assign-support-tickets-to-ai": false, "show-open-ai-api-instructions": false}}</script>

<div data-component="ModelDetailButton"
     data-props="react-component-props-b65cbf38-4788-404d-a754-2ccf81b91123">
  
</div>

    </div>
  </div>
</div>


  



<div class="flex flex-col gap-2 w-full">
  
    <div class="flex gap-4 flex-col md:flex-row items-start">
      
        <p class="max-w-3xl text-r8-lg [overflow-wrap:anywhere] text-pretty">
          
            New and improved version of Veo 3, with higher-fidelity video, context-aware audio, reference image and last frame support
            
          
        </p>
      
    </div>
  

  
</div>

<div class="w-full">
  <div class="space-y-4 @container">

    <div class="gap-y-2 items-start @xl:items-center grid @xl:flex @xl:flex-wrap @xl:flex-row @xs:grid-cols-2 gap-x-2 @xl:gap-x-6">

      
        <div class="flex items-center">
          <script id="react-component-props-0fcd253b-abf7-4181-9da8-86421e2cd02f" type="application/json">{"initialStatus": "online", "model": {"cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/7600d853-2847-4c46-afc9-faef04fea2c5/veo3.1-sm.mp4", "description": "New and improved version of Veo 3, with higher-fidelity video, context-aware audio, reference image and last frame support", "hardware": "CPU", "latest_version": {"id": "20ebd92c5919f20e8fa2e983bdb60016a99794c9accfab496ea25a68e0dbbaad"}, "name": "veo-3.1", "owner": "google", "url": "https://replicate.com/google/veo-3.1", "visibility": "public", "_extras": {"name": "google/veo-3.1", "is_official": true, "is_pipeline": false}}, "isOfficialModel": "", "__flags": {"show-pylon-widget": false, "assign-support-tickets-to-ai": false, "show-open-ai-api-instructions": false}}</script>

  <div data-react-placeholder="ModelStatusIndicator">
    <div class="flex items-center">
  <div class="rounded-full bg-r8-gray-3 animate-pulse w-[64px] h-[29px]">
  </div>
</div>

  </div>

<div data-component="ModelStatusIndicator"
     data-props="react-component-props-0fcd253b-abf7-4181-9da8-86421e2cd02f">
  
</div>

        </div>
      

      <div class="flex items-start gap-2">
        
          <span class="flex-shrink-0 -mt-0.5">
            <svg class="icon"
     fill="currentColor"
     xmlns="http://www.w3.org/2000/svg"
     viewBox="0 0 256 256">
  <rect width="256" height="256" fill="none" />
  <path d="M54.46,201.54c-9.2-9.2-3.1-28.53-7.78-39.85C41.82,150,24,140.5,24,128s17.82-22,22.68-33.69C51.36,83,45.26,63.66,54.46,54.46S83,51.36,94.31,46.68C106.05,41.82,115.5,24,128,24S150,41.82,161.69,46.68c11.32,4.68,30.65-1.42,39.85,7.78s3.1,28.53,7.78,39.85C214.18,106.05,232,115.5,232,128S214.18,150,209.32,161.69c-4.68,11.32,1.42,30.65-7.78,39.85s-28.53,3.1-39.85,7.78C150,214.18,140.5,232,128,232s-22-17.82-33.69-22.68C83,204.64,63.66,210.74,54.46,201.54Z" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="16" />
  <polyline points="88 136 112 160 168 104" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="16" />
</svg>

          </span>
          <span class="text-r8-sm"><script id="react-component-props-80741b48-fa26-414d-9419-a6abb5a360d5" type="application/json">{"anchorText": "Official", "anchorHref": "https://replicate.com/docs/topics/models/official-models", "tooltipText": "Official models are always on, maintained, and have predictable pricing.", "__flags": {"show-pylon-widget": false, "assign-support-tickets-to-ai": false, "show-open-ai-api-instructions": false}}</script>

<div data-component="TextTooltip"
     data-props="react-component-props-80741b48-fa26-414d-9419-a6abb5a360d5">
  
</div>
</span>
        
      </div>

      
        <div class="flex items-start gap-2">
          <span class="flex-shrink-0 -mt-0.5">
            
<svg class="icon"
     xmlns="http://www.w3.org/2000/svg"
     viewBox="0 0 24 24"
     width="24"
     height="24">
  <path fill="currentColor" fill-rule="evenodd" d="M20.322.75a10.75 10.75 0 00-7.373 2.926l-1.304 1.23A23.743 23.743 0 0010.103 6.5H5.066a1.75 1.75 0 00-1.5.85l-2.71 4.514a.75.75 0 00.49 1.12l4.571.963c.039.049.082.096.129.14L8.04 15.96l1.872 1.994c.044.047.091.09.14.129l.963 4.572a.75.75 0 001.12.488l4.514-2.709a1.75 1.75 0 00.85-1.5v-5.038a23.741 23.741 0 001.596-1.542l1.228-1.304a10.75 10.75 0 002.925-7.374V2.499A1.75 1.75 0 0021.498.75h-1.177zM16 15.112c-.333.248-.672.487-1.018.718l-3.393 2.262.678 3.223 3.612-2.167a.25.25 0 00.121-.214v-3.822zm-10.092-2.7L8.17 9.017c.23-.346.47-.685.717-1.017H5.066a.25.25 0 00-.214.121l-2.167 3.612 3.223.679zm8.07-7.644a9.25 9.25 0 016.344-2.518h1.177a.25.25 0 01.25.25v1.176a9.25 9.25 0 01-2.517 6.346l-1.228 1.303a22.248 22.248 0 01-3.854 3.257l-3.288 2.192-1.743-1.858a.764.764 0 00-.034-.034l-1.859-1.744 2.193-3.29a22.248 22.248 0 013.255-3.851l1.304-1.23zM17.5 8a1.5 1.5 0 11-3 0 1.5 1.5 0 013 0zm-11 13c.9-.9.9-2.6 0-3.5-.9-.9-2.6-.9-3.5 0-1.209 1.209-1.445 3.901-1.49 4.743a.232.232 0 00.247.247c.842-.045 3.534-.281 4.743-1.49z">
  </path>
</svg>

          </span>
          <span class="text-r8-sm whitespace-nowrap">65.3K
            runs
          </span>
        </div>

        
          <div class="[&>div]:flex">
            
            <script id="react-component-props-5b96d50a-da06-4e79-9119-3f189158ab3e" type="application/json">{"version": {"id": "0783cffef24d5269680f49b1dc928b17fc8464ed16f1d122759d424eea0972c5", "created_at": "2025-11-07T13:41:12.430973Z", "_extras": {"arch": "cpu", "dereferenced_openapi_schema": {"info": {"title": "Cog", "version": "0.1.0"}, "paths": {"/": {"get": {"summary": "Root", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Root  Get"}}}, "description": "Successful Response"}}, "operationId": "root__get"}}, "/shutdown": {"post": {"summary": "Start Shutdown", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Start Shutdown Shutdown Post"}}}, "description": "Successful Response"}}, "operationId": "start_shutdown_shutdown_post"}}, "/predictions": {"post": {"summary": "Predict", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model", "operationId": "predict_predictions_post", "requestBody": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}}}}}}, "/health-check": {"get": {"summary": "Healthcheck", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Healthcheck Health Check Get"}}}, "description": "Successful Response"}}, "operationId": "healthcheck_health_check_get"}}, "/predictions/{prediction_id}": {"put": {"summary": "Predict Idempotent", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}, {"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model (idempotent creation).", "operationId": "predict_idempotent_predictions__prediction_id__put", "requestBody": {"content": {"application/json": {"schema": {"allOf": [{"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}], "title": "Prediction Request"}}}, "required": true}}}, "/predictions/{prediction_id}/cancel": {"post": {"summary": "Cancel", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Cancel Predictions  Prediction Id  Cancel Post"}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}], "description": "Cancel a running prediction", "operationId": "cancel_predictions__prediction_id__cancel_post"}}}, "openapi": "3.0.2", "components": {"schemas": {"Input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "Output": {"type": "string", "title": "Output", "format": "uri"}, "Status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "An enumeration."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "An enumeration."}, "WebhookEvent": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "An enumeration."}, "ValidationError": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "PredictionRequest": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}, "PredictionResponse": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}, "HTTPValidationError": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}}, "disabled_for_predictions": false, "disabled_for_trainings": false, "model": {"cover_image_url": null, "description": null, "hardware": null, "latest_version": {"id": "0783cffef24d5269680f49b1dc928b17fc8464ed16f1d122759d424eea0972c5"}, "name": "google-veo-3.1", "owner": "replicate", "url": "https://replicate.com/replicate/google-veo-3.1", "visibility": "private", "_extras": {"name": "replicate/google-veo-3.1", "is_official": false, "is_pipeline": false}}, "name": "replicate/google-veo-3.1:0783cffe", "release_notes": null, "short_id": "0783cffe", "url": "https://replicate.com/replicate/google-veo-3.1/versions/0783cffef24d5269680f49b1dc928b17fc8464ed16f1d122759d424eea0972c5"}}, "hardware": "CPU", "billingConfig": {"current_description": null, "current_tiers": [{"criteria": [{"description": "with_audio", "subtype": "string", "title": "model variant", "type": "equals", "value": "with_audio"}], "description": null, "prices": [{"description": "or 25 seconds for $10", "metric": "video_output_duration_seconds", "metric_display": "second of output video", "price": "$0.40", "title": "per second of output video", "type": "per-unit"}], "title": null}, {"criteria": [{"description": "without_audio", "subtype": "string", "title": "model variant", "type": "equals", "value": "without_audio"}], "description": null, "prices": [{"description": "or 50 seconds for $10", "metric": "video_output_duration_seconds", "metric_display": "second of output video", "price": "$0.20", "title": "per second of output video", "type": "per-unit"}], "title": null}]}, "price": "$0.0001 per second", "p50price": "$0.010", "model": {"cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/7600d853-2847-4c46-afc9-faef04fea2c5/veo3.1-sm.mp4", "description": "New and improved version of Veo 3, with higher-fidelity video, context-aware audio, reference image and last frame support", "hardware": "CPU", "latest_version": {"id": "20ebd92c5919f20e8fa2e983bdb60016a99794c9accfab496ea25a68e0dbbaad"}, "name": "veo-3.1", "owner": "google", "url": "https://replicate.com/google/veo-3.1", "visibility": "public", "_extras": {"name": "google/veo-3.1", "is_official": true, "is_pipeline": false}}, "__flags": {"show-pylon-widget": false, "assign-support-tickets-to-ai": false, "show-open-ai-api-instructions": false}}</script>

<div data-component="ModelPricePopover"
     data-props="react-component-props-5b96d50a-da06-4e79-9119-3f189158ab3e">
  
</div>

          </div>
        
      

      
        <div class="flex items-start gap-2">
          <i class="-mt-0.5">
            
<svg xmlns="http://www.w3.org/2000/svg"
     width="24"
     height="24"
     viewBox="0 0 24 24"
     fill="none"
     stroke="currentColor"
     stroke-width="2"
     stroke-linecap="round"
     stroke-linejoin="round"
     class="icon">
  <polyline points="20 6 9 17 4 12"></polyline>
</svg>

          </i>
          <div class="text-r8-sm">
            <script id="react-component-props-f5770dcc-3b5b-4ab9-845a-757db3b7c992" type="application/json">{"anchorHref": null, "anchorText": "Commercial use", "tooltipText": "Outputs from this model can be sold or used in paid products.", "__flags": {"show-pylon-widget": false, "assign-support-tickets-to-ai": false, "show-open-ai-api-instructions": false}}</script>

<div data-component="TextTooltip"
     data-props="react-component-props-f5770dcc-3b5b-4ab9-845a-757db3b7c992">
  
</div>

          </div>
        </div>
      

      

      

      

    </div>

    

  </div>
</div>


</header>

    
    
      
        <div class="border-b border-r8-gray-6">
          






<div class="r8-tabs r8-tabs--bordered r8-tabs--md top-px relative flex-wrap">
  
    <a href="/google/veo-3.1"
       aria-selected="true"
       class="r8-tabs__tab no-underline">
      <span class="r8-tabs__start-icon">
        <svg class="icon"
     xmlns="http://www.w3.org/2000/svg"
     width="24"
     height="24"
     viewBox="0 0 24 24"
     fill="none"
     stroke="currentColor"
     stroke-width="1.5"
     stroke-linecap="round"
     stroke-linejoin="round">
  <polygon points="5 3 19 12 5 21 5 3"></polygon>

</svg>

      </span>
      <span>Playground</span>
    </a>
  

  
    
      <a href="/google/veo-3.1/api"
         
         class="r8-tabs__tab no-underline">

        <span class="r8-tabs__start-icon">
          
<svg class="icon"
     xmlns="http://www.w3.org/2000/svg"
     viewBox="0 0 24 24"
     width="24"
     height="24">
  <path fill="currentColor" fill-rule="evenodd" d="M20.322.75a10.75 10.75 0 00-7.373 2.926l-1.304 1.23A23.743 23.743 0 0010.103 6.5H5.066a1.75 1.75 0 00-1.5.85l-2.71 4.514a.75.75 0 00.49 1.12l4.571.963c.039.049.082.096.129.14L8.04 15.96l1.872 1.994c.044.047.091.09.14.129l.963 4.572a.75.75 0 001.12.488l4.514-2.709a1.75 1.75 0 00.85-1.5v-5.038a23.741 23.741 0 001.596-1.542l1.228-1.304a10.75 10.75 0 002.925-7.374V2.499A1.75 1.75 0 0021.498.75h-1.177zM16 15.112c-.333.248-.672.487-1.018.718l-3.393 2.262.678 3.223 3.612-2.167a.25.25 0 00.121-.214v-3.822zm-10.092-2.7L8.17 9.017c.23-.346.47-.685.717-1.017H5.066a.25.25 0 00-.214.121l-2.167 3.612 3.223.679zm8.07-7.644a9.25 9.25 0 016.344-2.518h1.177a.25.25 0 01.25.25v1.176a9.25 9.25 0 01-2.517 6.346l-1.228 1.303a22.248 22.248 0 01-3.854 3.257l-3.288 2.192-1.743-1.858a.764.764 0 00-.034-.034l-1.859-1.744 2.193-3.29a22.248 22.248 0 013.255-3.851l1.304-1.23zM17.5 8a1.5 1.5 0 11-3 0 1.5 1.5 0 013 0zm-11 13c.9-.9.9-2.6 0-3.5-.9-.9-2.6-.9-3.5 0-1.209 1.209-1.445 3.901-1.49 4.743a.232.232 0 00.247.247c.842-.045 3.534-.281 4.743-1.49z">
  </path>
</svg>

        </span>
        <span>API</span>
      </a>
    
  

  
    <a href="/google/veo-3.1/examples"
       
       class="r8-tabs__tab no-underline">
      <span class="r8-tabs__start-icon">
        <svg class="icon"
     xmlns="http://www.w3.org/2000/svg"
     width="24"
     height="24"
     viewBox="0 0 24 24"
     fill="none"
     stroke="currentColor"
     stroke-width="1.5"
     stroke-linecap="round"
     stroke-linejoin="round">
  <rect x="3" y="3" width="18" height="18" rx="2" ry="2"></rect>
  <polyline points="11 3 11 11 14 8 17 11 17 3"></polyline>
</svg>

      </span>
      <span>Examples</span>
    </a>
  

  

  <a href="/google/veo-3.1/readme"
     
     class="r8-tabs__tab no-underline">
    <span class="r8-tabs__start-icon">
      
<svg xmlns="http://www.w3.org/2000/svg"
     width="24"
     height="24"
     viewBox="0 0 24 24"
     fill="none"
     stroke="currentColor"
     stroke-width="1.5"
     stroke-linecap="round"
     stroke-linejoin="round"
     class="icon">
  <path d="M14.5 2H6a2 2 0 00-2 2v16a2 2 0 002 2h12a2 2 0 002-2V7.5L14.5 2z">
  </path>
  <polyline points="14 2 14 8 20 8"></polyline>
  <line x1="16" y1="13" x2="8" y2="13"></line>
  <line x1="16" y1="17" x2="8" y2="17"></line>
  <line x1="10" y1="9" x2="8" y2="9"></line>
</svg>

    </span>
    <span>README</span>
  </a>

  
    
  

  

  

  
</div>

        </div>
      
    

    

  
    
  


  
    <div class="model-content mt-lh">
      
  
    

<div class="mb-2lh">
  
  
  
    <script id="react-component-props-de2fdb88-2074-4635-abb0-df5e2277df98" type="application/json">{"initialPrediction": {"completed_at": "2025-10-15T10:33:46.386292Z", "created_at": "2025-10-15T10:32:04.431000Z", "data_removed": false, "error": null, "id": "zmzn6n2e9xrme0cswxpr4z734g", "input": {"prompt": "the woman is giving an interview for a podcast, wearing a pink top with the logo, it also neatly says \"Veo 3.1\", she is in a midcentury modern studio with pink lighting, she talks about using Veo 3.1 with reference images to put things into videos you're making, the logo is also in a framed picture against black behind her", "duration": 8, "resolution": "1080p", "aspect_ratio": "16:9", "generate_audio": true, "reference_images": ["https://replicate.delivery/pbxt/Nt8bL90QO5In3RDkC82HtqeXqNdITglTVpaicTgrdT8mtjiW/0_1.webp", "https://replicate.delivery/pbxt/Nt8bLbk1uz4EIMWhIQ0DyjO8BGJYYeAgQWgEnFUWNMOGEpbU/Screenshot%202025-08-26%20at%205.30.12%E2%80%AFPM.png"]}, "logs": "Using seed: 310333719\nStarting video generation...\nStill generating...\nStill generating...\nGenerated video in 99.76 seconds\nDownloading video...\nDownloaded video in 0.42 seconds", "metrics": {"predict_time": 101.787063821, "total_time": 101.955292}, "output": "https://replicate.delivery/xezq/WoC3evx2EQQHLCHq9vEfjhIq9ZotfQhQWmBEd54iLhvVUleVB/tmpk07h98l4.mp4", "started_at": "2025-10-15T10:32:04.599228Z", "status": "succeeded", "urls": {"stream": "https://stream.replicate.com/v1/files/bcwr-dtwll5wxvdhbvvir22ncvcnn6ya53m4wo4or3vlqnpc7qkqpkr4a", "get": "https://api.replicate.com/v1/predictions/zmzn6n2e9xrme0cswxpr4z734g", "cancel": "https://api.replicate.com/v1/predictions/zmzn6n2e9xrme0cswxpr4z734g/cancel"}, "_extras": {"api_token_name": null, "created_by": {"kind": "organization", "url": "https://replicate.com/google", "username": "google"}, "input_files": ["https://replicate.delivery/pbxt/Nt8bL90QO5In3RDkC82HtqeXqNdITglTVpaicTgrdT8mtjiW/0_1.webp", "https://replicate.delivery/pbxt/Nt8bLbk1uz4EIMWhIQ0DyjO8BGJYYeAgQWgEnFUWNMOGEpbU/Screenshot%202025-08-26%20at%205.30.12%E2%80%AFPM.png"], "is_immutable": false, "is_shared": false, "is_waiting_for_boot": null, "may_have_sensitive_output": false, "output_files": ["https://replicate.delivery/xezq/WoC3evx2EQQHLCHq9vEfjhIq9ZotfQhQWmBEd54iLhvVUleVB/tmpk07h98l4.mp4"], "pipeline_child_predictions": [], "ran_on": {"capabilities": {"hotswap": false, "run": true, "stream": false, "train": false}, "dereferenced_openapi_schema": {"info": {"title": "Cog", "version": "0.1.0"}, "paths": {"/": {"get": {"summary": "Root", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Root  Get"}}}, "description": "Successful Response"}}, "operationId": "root__get"}}, "/shutdown": {"post": {"summary": "Start Shutdown", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Start Shutdown Shutdown Post"}}}, "description": "Successful Response"}}, "operationId": "start_shutdown_shutdown_post"}}, "/predictions": {"post": {"summary": "Predict", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model", "operationId": "predict_predictions_post", "requestBody": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}}}}}}, "/health-check": {"get": {"summary": "Healthcheck", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Healthcheck Health Check Get"}}}, "description": "Successful Response"}}, "operationId": "healthcheck_health_check_get"}}, "/predictions/{prediction_id}": {"put": {"summary": "Predict Idempotent", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}, {"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model (idempotent creation).", "operationId": "predict_idempotent_predictions__prediction_id__put", "requestBody": {"content": {"application/json": {"schema": {"allOf": [{"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}], "title": "Prediction Request"}}}, "required": true}}}, "/predictions/{prediction_id}/cancel": {"post": {"summary": "Cancel", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Cancel Predictions  Prediction Id  Cancel Post"}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}], "description": "Cancel a running prediction", "operationId": "cancel_predictions__prediction_id__cancel_post"}}}, "openapi": "3.0.2", "components": {"schemas": {"Input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "Output": {"type": "string", "title": "Output", "format": "uri"}, "Status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "An enumeration."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "An enumeration."}, "WebhookEvent": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "An enumeration."}, "ValidationError": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "PredictionRequest": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}, "PredictionResponse": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}, "HTTPValidationError": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}}, "hardware": {"arch": "cpu", "display_name": "CPU", "short_display_name": "CPU", "sku": "cpu"}, "has_special_pricing": true, "is_official": true, "kind": "model", "model": {"name": "veo-3.1", "username": "google", "visibility": "public"}, "supports_cancelation": false, "url": "https://replicate.com/google/veo-3.1"}, "source": "web", "total_child_predictions": 0}, "version": "hidden"}, "initialPredictionVersion": {"id": "4e4f06dd591a5700f1c54382caf153365581c1b0f4743047f816e895f122209e", "created_at": "2025-10-15T10:30:01.679568Z", "_extras": {"arch": "cpu", "dereferenced_openapi_schema": {"info": {"title": "Cog", "version": "0.1.0"}, "paths": {"/": {"get": {"summary": "Root", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Root  Get"}}}, "description": "Successful Response"}}, "operationId": "root__get"}}, "/shutdown": {"post": {"summary": "Start Shutdown", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Start Shutdown Shutdown Post"}}}, "description": "Successful Response"}}, "operationId": "start_shutdown_shutdown_post"}}, "/predictions": {"post": {"summary": "Predict", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model", "operationId": "predict_predictions_post", "requestBody": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}}}}}}, "/health-check": {"get": {"summary": "Healthcheck", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Healthcheck Health Check Get"}}}, "description": "Successful Response"}}, "operationId": "healthcheck_health_check_get"}}, "/predictions/{prediction_id}": {"put": {"summary": "Predict Idempotent", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}, {"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model (idempotent creation).", "operationId": "predict_idempotent_predictions__prediction_id__put", "requestBody": {"content": {"application/json": {"schema": {"allOf": [{"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}], "title": "Prediction Request"}}}, "required": true}}}, "/predictions/{prediction_id}/cancel": {"post": {"summary": "Cancel", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Cancel Predictions  Prediction Id  Cancel Post"}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}], "description": "Cancel a running prediction", "operationId": "cancel_predictions__prediction_id__cancel_post"}}}, "openapi": "3.0.2", "components": {"schemas": {"Input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "Output": {"type": "string", "title": "Output", "format": "uri"}, "Status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "An enumeration."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "An enumeration."}, "WebhookEvent": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "An enumeration."}, "ValidationError": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "PredictionRequest": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}, "PredictionResponse": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}, "HTTPValidationError": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}}, "disabled_for_predictions": false, "disabled_for_trainings": false, "model": {"cover_image_url": null, "description": null, "hardware": null, "latest_version": {"id": "0783cffef24d5269680f49b1dc928b17fc8464ed16f1d122759d424eea0972c5"}, "name": "google-veo-3.1", "owner": "replicate", "url": "https://replicate.com/replicate/google-veo-3.1", "visibility": "private", "_extras": {"name": "replicate/google-veo-3.1", "is_official": false, "is_pipeline": false}}, "name": "replicate/google-veo-3.1:4e4f06dd", "release_notes": null, "short_id": "4e4f06dd", "url": "https://replicate.com/replicate/google-veo-3.1/versions/4e4f06dd591a5700f1c54382caf153365581c1b0f4743047f816e895f122209e"}}, "isAuthenticated": false, "features": {"show_pipeline_steps": false, "show_before_after_slider_output": false, "show_goo_shader_output": false, "link_to_video_upscaler": false, "link_to_image_upscaler": false, "link_to_playground": true, "link_to_audio_adder": false, "pixelate_images": false}, "permissions": {"create_example": false, "debug": false, "edit_featured_inputs": false, "report": true, "run": false, "tweak": true, "delete": false, "share": true}, "model": {"cover_image_url": "https://tjzk.replicate.delivery/models_models_featured_image/7600d853-2847-4c46-afc9-faef04fea2c5/veo3.1-sm.mp4", "description": "New and improved version of Veo 3, with higher-fidelity video, context-aware audio, reference image and last frame support", "hardware": "CPU", "latest_version": {"id": "20ebd92c5919f20e8fa2e983bdb60016a99794c9accfab496ea25a68e0dbbaad"}, "name": "veo-3.1", "owner": "google", "url": "https://replicate.com/google/veo-3.1", "visibility": "public", "_extras": {"name": "google/veo-3.1", "is_official": true, "is_pipeline": false}}, "schema": {"info": {"title": "Cog", "version": "0.1.0"}, "paths": {"/": {"get": {"summary": "Root", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Root  Get"}}}, "description": "Successful Response"}}, "operationId": "root__get"}}, "/shutdown": {"post": {"summary": "Start Shutdown", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Start Shutdown Shutdown Post"}}}, "description": "Successful Response"}}, "operationId": "start_shutdown_shutdown_post"}}, "/predictions": {"post": {"summary": "Predict", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model", "operationId": "predict_predictions_post", "requestBody": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}}}}}}, "/health-check": {"get": {"summary": "Healthcheck", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Healthcheck Health Check Get"}}}, "description": "Successful Response"}}, "operationId": "healthcheck_health_check_get"}}, "/predictions/{prediction_id}": {"put": {"summary": "Predict Idempotent", "responses": {"200": {"content": {"application/json": {"schema": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}, {"in": "header", "name": "prefer", "schema": {"type": "string", "title": "Prefer"}, "required": false}], "description": "Run a single prediction on the model (idempotent creation).", "operationId": "predict_idempotent_predictions__prediction_id__put", "requestBody": {"content": {"application/json": {"schema": {"allOf": [{"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}], "title": "Prediction Request"}}}, "required": true}}}, "/predictions/{prediction_id}/cancel": {"post": {"summary": "Cancel", "responses": {"200": {"content": {"application/json": {"schema": {"title": "Response Cancel Predictions  Prediction Id  Cancel Post"}}}, "description": "Successful Response"}, "422": {"content": {"application/json": {"schema": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}, "description": "Validation Error"}}, "parameters": [{"in": "path", "name": "prediction_id", "schema": {"type": "string", "title": "Prediction ID"}, "required": true}], "description": "Cancel a running prediction", "operationId": "cancel_predictions__prediction_id__cancel_post"}}}, "openapi": "3.0.2", "components": {"schemas": {"Input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "Output": {"type": "string", "title": "Output", "format": "uri"}, "Status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "An enumeration."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "An enumeration."}, "WebhookEvent": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "An enumeration."}, "ValidationError": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "PredictionRequest": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "context": {"type": "object", "title": "Context", "nullable": true, "additionalProperties": {"type": "string"}}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "nullable": true, "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "output_file_prefix": {"type": "string", "title": "Output File Prefix", "nullable": true}, "webhook_events_filter": {"type": "array", "items": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "default": ["start", "output", "logs", "completed"], "nullable": true}}}, "PredictionResponse": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id", "nullable": true}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error", "nullable": true}, "input": {"type": "object", "title": "Input", "required": ["prompt"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 9, "nullable": true, "description": "Random seed. Omit for random generations"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 3, "nullable": true, "description": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose."}, "prompt": {"type": "string", "title": "Prompt", "x-order": 0, "description": "Text prompt for video generation"}, "duration": {"enum": [4, 6, 8], "type": "integer", "title": "duration", "description": "Video duration in seconds", "default": 8, "x-order": 2}, "last_frame": {"type": "string", "title": "Last Frame", "format": "uri", "x-order": 4, "nullable": true, "description": "Ending image for interpolation. When provided with an input image, creates a transition between the two images."}, "resolution": {"enum": ["720p", "1080p"], "type": "string", "title": "resolution", "description": "Resolution of the generated video", "default": "1080p", "x-order": 7}, "aspect_ratio": {"enum": ["16:9", "9:16"], "type": "string", "title": "aspect_ratio", "description": "Video aspect ratio", "default": "16:9", "x-order": 1}, "generate_audio": {"type": "boolean", "title": "Generate Audio", "default": true, "x-order": 8, "description": "Generate audio with the video"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "x-order": 6, "nullable": true, "description": "Description of what to exclude from the generated video"}, "reference_images": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Reference Images", "default": [], "x-order": 5, "description": "1 to 3 reference images for subject-consistent generation (reference-to-video, or R2V). Reference images only work with 16:9 aspect ratio and 8-second duration. Last frame is ignored if reference images are provided."}}}, "output": {"type": "string", "title": "Output", "format": "uri"}, "status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "metrics": {"type": "object", "title": "Metrics", "nullable": true, "additionalProperties": true}, "version": {"type": "string", "title": "Version", "nullable": true}, "created_at": {"type": "string", "title": "Created At", "format": "date-time", "nullable": true}, "started_at": {"type": "string", "title": "Started At", "format": "date-time", "nullable": true}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time", "nullable": true}}}, "HTTPValidationError": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "title": "Detail"}}}}}}, "token": "", "modelStatus": "online", "modelInputSettings": {"hidden": []}, "requiresCredit": true, "__flags": {"show-pylon-widget": false, "assign-support-tickets-to-ai": false, "show-open-ai-api-instructions": false}}</script>

  <div data-react-placeholder="APIPlayground">
    <div class="input-output-grid">
  <div class="flex flex-col md:flex-row">
    <div class="input-col relative md:flex-1 pb-4 min-w-0">
      <div class="mb-2 flex items-center justify-between">
        <div class="flex-1">
          <div class="mb-4 bg-r8-gray-4 animate-pulse h-8 w-24">
          </div>
        </div>
      </div>
      <div class="h-8 bg-r8-gray-4 animate-pulse mb-6">
      </div>
      <div class="space-y-4">
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
          <div class="flex flex-col space-y-2">
            <div class="w-24 h-4 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-full h-8 bg-r8-gray-4 animate-pulse">
            </div>
            <div class="w-3/4 h-4 bg-r8-gray-4 animate-pulse">
            </div>
          </div>
        
      </div>
    </div>
    <div class="input-output-grid--divider flex-shrink-0 md:mx-6 mb-6 md:my-0"
         role="separator">
      <div class="bg-r8-gray-6 md:w-px md:h-full h-px w-full">
      </div>
    </div>
    <div class="output-col md:flex-1 pb-4 min-w-0">
      <div class="flex flex-col">
        <div class="flex-1">
          <div class="mb-4 bg-r8-gray-4 animate-pulse h-8 w-24">
          </div>
        </div>
        <div class="h-8 bg-r8-gray-4 animate-pulse mb-6">
        </div>
        <div class="aspect-square bg-r8-gray-4 animate-pulse">
        </div>
      </div>
    </div>
  </div>
</div>

  </div>

<div data-component="APIPlayground"
     data-props="react-component-props-de2fdb88-2074-4635-abb0-df5e2277df98">
  
</div>

  
</div>

    



  
  
  
    <div class="pb-2 border-b border-r8-gray-5 mb-lh flex">
      <h2 class="inline-block flex-grow text-r8-2xl">
        Examples
      </h2>

      <p>
        <a href="/google/veo-3.1/examples"
           class="no-default">
          View more <span class="hidden sm:inline">examples</span><span class="relative -top-0.5">
          
<svg xmlns="http://www.w3.org/2000/svg"
     width="24"
     height="24"
     viewBox="0 0 24 24"
     fill="none"
     stroke="currentColor"
     stroke-width="1.5"
     stroke-linecap="round"
     stroke-linejoin="round"
     class="icon">
  <line x1="7" y1="17" x2="17" y2="7"></line>
  <polyline points="7 7 17 7 17 17"></polyline>
</svg>

        </span></a>
      </p>
    </div>

    <div class="mb-2lh h-40 overflow-hidden ">
      
        
          <div class="inline-block h-40 w-40 overflow-hidden">
            <a class="relative"
               href="/google/veo-3.1/examples#zmzn6n2e9xrme0cswxpr4z734g">

              
                <video data-src="https://replicate.delivery/xezq/WoC3evx2EQQHLCHq9vEfjhIq9ZotfQhQWmBEd54iLhvVUleVB/tmpk07h98l4.mp4"
                       type="video/mp4"
                       autoplay
                       muted
                       loop
                       role="presentation"
                       class="object-cover object-center w-full h-full lazy" />
              

            </a>
          </div>
        
      
        
          <div class="inline-block h-40 w-40 overflow-hidden">
            <a class="relative"
               href="/google/veo-3.1/examples#x3c92sahahrmc0cswyp8srjjy8">

              
                <video data-src="https://replicate.delivery/xezq/MDBpHsfnFuS2TiCNuXM0QGghQ83rAuHikI5x9heoWs2mqTfqA/tmp62g_gnbr.mp4"
                       type="video/mp4"
                       autoplay
                       muted
                       loop
                       role="presentation"
                       class="object-cover object-center w-full h-full lazy" />
              

            </a>
          </div>
        
      
        
          <div class="inline-block h-40 w-40 overflow-hidden">
            <a class="relative"
               href="/google/veo-3.1/examples#7a6v7zv0qhrmc0csx22rdrd568">

              
                <video data-src="https://replicate.delivery/xezq/69ok3gifKESec04GfPMaTU2YShWMSL37elrN7dQ3QJmeD56rC/tmpvruiwe2d.mp4"
                       type="video/mp4"
                       autoplay
                       muted
                       loop
                       role="presentation"
                       class="object-cover object-center w-full h-full lazy" />
              

            </a>
          </div>
        
      
        
          <div class="inline-block h-40 w-40 overflow-hidden">
            <a class="relative"
               href="/google/veo-3.1/examples#aa7d67zht9rm80csx6aa5ncsww">

              
                <video data-src="https://replicate.delivery/xezq/hpxa0wn2og7aIRife9Xlvu0OGeS1qaz45bl43foW3rL58t9VB/tmpgnyhwssx.mp4"
                       type="video/mp4"
                       autoplay
                       muted
                       loop
                       role="presentation"
                       class="object-cover object-center w-full h-full lazy" />
              

            </a>
          </div>
        
      
    </div>
  




    
      

<section id="pricing"
         class="mb-2lh">

  <script id="react-component-props-5d9f0f3d-f14f-4927-983a-e901b074f7fd" type="application/json">{"billingConfig": {"current_description": null, "current_tiers": [{"criteria": [{"description": "with_audio", "subtype": "string", "title": "model variant", "type": "equals", "value": "with_audio"}], "description": null, "prices": [{"description": "or 25 seconds for $10", "metric": "video_output_duration_seconds", "metric_display": "second of output video", "price": "$0.40", "title": "per second of output video", "type": "per-unit"}], "title": null}, {"criteria": [{"description": "without_audio", "subtype": "string", "title": "model variant", "type": "equals", "value": "without_audio"}], "description": null, "prices": [{"description": "or 50 seconds for $10", "metric": "video_output_duration_seconds", "metric_display": "second of output video", "price": "$0.20", "title": "per second of output video", "type": "per-unit"}], "title": null}]}, "modelName": "google/veo-3.1", "showTable": false, "__flags": {"show-pylon-widget": false, "assign-support-tickets-to-ai": false, "show-open-ai-api-instructions": false}}</script>

<div data-component="ModelBilling"
     data-props="react-component-props-5d9f0f3d-f14f-4927-983a-e901b074f7fd">
  
</div>

</section>

    

    

<article class="mb-2lh">
  
    <div id="readme"
         class="border-b border-r8-gray-5 pb-2 mb-lh flex items-center gap-2">
      <h2 class="inline-block text-r8-2xl">
        Readme
      </h2>
      
    </div>
  
  
    <div class="readme-prose max-w-4xl">
      <h1 id="veo-31">Veo 3.1</h1>
<p>Googleâ€™s state-of-the-art video generation model that creates high-quality videos with synchronized native audio from text prompts or images. Veo 3.1 offers enhanced prompt adherence, improved audiovisual quality, and powerful creative controls for image-to-video generation.</p>
<h2 id="key-features">Key Features</h2>
<p><strong>Synchronized Audio Generation</strong> â€“ Veo 3.1 generates rich native audio automatically, from natural conversations and sound effects to ambient soundscapes, perfectly synchronized with your video content.</p>
<p><strong>Enhanced Image-to-Video</strong> â€“ Transform static images into dynamic videos with superior prompt adherence and visual quality. Veo 3.1 excels at maintaining character consistency and understanding your creative vision.</p>
<p><strong>Superior Prompt Understanding</strong> â€“ The model demonstrates remarkable comprehension of complex, nuanced prompts including intricate scenes, specific camera movements, and detailed artistic styles that previous models often missed.</p>
<p><strong>Realistic Physics and Motion</strong> â€“ Veo 3.1 delivers true-to-life textures, coherent motion across frames, and improved realism capturing natural movement and interactions.</p>
<p><strong>Reference Image Support</strong> â€“ Upload up to 3 reference images to guide the appearance, style, and character consistency across your generated video, ensuring visual continuity throughout.</p>
<p><strong>Frame-to-Frame Generation</strong> â€“ Provide a starting and ending frame, and Veo 3.1 generates smooth, seamless transitions between them, perfect for creating artful scene transitions.</p>
<p><strong>Scene Extension</strong> â€“ Extend your videos beyond the initial generation, creating longer sequences that maintain visual and audio consistency by building on the final seconds of your previous clip.</p>
<p><strong>Multiple Output Formats</strong> â€“ Generate videos at 720p or 1080p resolution at 24 FPS, with support for both landscape (16:9) and portrait (9:16) aspect ratios. Choose from 4, 6, or 8-second durations.</p>
<p><strong>Cinematic Quality</strong> â€“ Veo 3.1 incorporates enhanced understanding of cinematic styles and narrative control, delivering more polished and professional-looking results.</p>
<h2 id="what-you-can-create">What You Can Create</h2>
<p><strong>Text-to-Video</strong> â€“ Describe your vision in natural language and watch it come to life with synchronized audio. From realistic scenes to fantastical concepts, Veo 3.1 translates your words into stunning visuals.</p>
<p><strong>Image-to-Video</strong> â€“ Animate your static images with lifelike motion and accompanying audio. Perfect for bringing concept art, photos, or illustrations to life.</p>
<p><strong>Character Consistency</strong> â€“ Maintain the same character appearance across multiple video generations using reference images, ideal for storytelling and creating cohesive content series.</p>
<p><strong>Cinematic Transitions</strong> â€“ Create smooth scene transitions by defining start and end frames, letting Veo 3.1 generate the motion in between with natural camera movement.</p>
<p><strong>Extended Sequences</strong> â€“ Build longer narratives by chaining multiple generations together, with each new clip seamlessly continuing from where the last one ended.</p>
<h2 id="best-practices">Best Practices</h2>
<p><strong>Crafting Effective Prompts</strong> â€“ Be specific and descriptive in your text prompts. Include details about camera angles, lighting, mood, and any audio elements you want. For example: â€œA medium shot of a wise owl circling above a moonlit forest clearing, with wings flapping sounds and a gentle orchestral score.â€</p>
<p><strong>Using Reference Images</strong> â€“ When using reference images for character or style consistency, choose clear, well-lit images that show the subject from the desired angle. You can provide 1-3 images to guide the generation.</p>
<p><strong>Image-to-Video Tips</strong> â€“ For best results with image-to-video, use high-quality input images with clear subjects. Your prompt should describe the motion and action you want to see, not just describe whatâ€™s already in the image.</p>
<p><strong>Audio Considerations</strong> â€“ While Veo 3.1 generates synchronized audio automatically, you can guide it by describing desired sounds in your prompt using tags or descriptions like â€œwith bird songs and wind rustlingâ€ or â€œaccompanied by upbeat music.â€</p>
<p><strong>Frame Control</strong> â€“ When using start and end frames, ensure theyâ€™re visually compatible and the transition youâ€™re requesting is physically plausible. The model works best with natural motion sequences.</p>
<h2 id="about-veo-31">About Veo 3.1</h2>
<p>Veo 3.1 builds on Googleâ€™s Veo 3 foundation with significant improvements in prompt adherence and audiovisual quality, particularly for image-to-video generation. The model was designed with creative professionals in mind, offering granular control over generated content while maintaining ease of use.</p>
<p>All videos generated with Veo 3.1 are marked with SynthID, Googleâ€™s watermarking technology for identifying AI-generated content. The model has been extensively tested for safety and content policy compliance.</p>
<p>Veo 3.1 also comes in a Fast variant (Veo 3.1 Fast) that offers faster generation times while maintaining high quality, perfect for rapid iteration and experimentation.</p>
<h2 id="learn-more">Learn More</h2>
<p>For detailed API documentation and the latest updates, visit <a href="https://ai.google.dev/gemini-api/docs" rel="nofollow ugc">Googleâ€™s Gemini API documentation</a>.</p>
<hr/>
<p><strong>Try the model yourself on the <a href="https://replicate.com/google/nano-banana" rel="nofollow ugc">Replicate Playground</a></strong> to explore its capabilities and see how it can enhance your creative workflow.</p>
    </div>
  
</article>

    




    <script id="react-component-props-75bef431-50ff-443a-a0c4-fd20f239e838" type="application/json">{"name": "google/veo-3.1", "__flags": {"show-pylon-widget": false, "assign-support-tickets-to-ai": false, "show-open-ai-api-instructions": false}}</script>

<div data-component="RelatedModels"
     data-props="react-component-props-75bef431-50ff-443a-a0c4-fd20f239e838">
  
</div>

  </div>


    </div>
  

  <div class="model-content mt-2lh">
    



  </div>



          
        
      </main>

      
        

<div class="footer no-focus">
  <script id="react-component-props-d7669686-a070-41d7-802c-7438ca70a830" type="application/json">{"theme": "", "__flags": {"show-pylon-widget": false, "assign-support-tickets-to-ai": false, "show-open-ai-api-instructions": false}}</script>

<div data-component="Footer"
     data-props="react-component-props-d7669686-a070-41d7-802c-7438ca70a830">
  
</div>

</div>

      

    

    <script nonce="PpHLkEzMSKoBkzLZ38Dg0Q==">
      window.VIDEOJS_NO_DYNAMIC_STYLE = true;
    </script>

    <script nonce="PpHLkEzMSKoBkzLZ38Dg0Q==">
      const header = document.getElementById("app-header");

      function monitorHeaderStickiness() {
        if (header) {
          header.setAttribute("data-stuck", window.scrollY > 0);
        }
      }

      monitorHeaderStickiness();

      document.addEventListener("scroll", (event) => {
        monitorHeaderStickiness();
      });

      // Prevent mousewheel from being able to change the value of a numeric input.
      // This "feature" often causes issues when users scroll from a focused input field
      // to the submit button and accidentally increment the contents of the field.
      document.addEventListener("wheel", (event) => {
        if (document.activeElement && document.activeElement.matches('input[type=number]') && document.activeElement === event.target) {
          event.preventDefault();
        }
      }, {
        passive: false
      });
    </script>

    
    
    

  </body>

</html>
